{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a312a11b",
   "metadata": {},
   "source": [
    "## TRT Conversion\n",
    "\n",
    "**References**\n",
    " \n",
    "https://github.com/deepinsight/insightface\n",
    "\n",
    "https://github.com/SthPhoenix/InsightFace-REST/tree/master/src/converters\n",
    "\n",
    "\n",
    "**Pre-requisites**\n",
    "\n",
    "`$ docker pull nvcr.io/nvidia/tensorrt:20.12-py3 `\n",
    "\n",
    "`$ docker run --gpus all -it --net=host -v /path/to/files:/workspace/insightface nvcr.io/nvidia/tensorrt:20.12-py3`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e7c28a8",
   "metadata": {},
   "source": [
    "**Container Installations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb49c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf8a569",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install onnx==1.8.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56030c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install mxnet==1.6.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5818f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "!bash /opt/tensorrt/install_opensource.sh -b master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b4cbf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir model_repository\n",
    "!mkdir model_repository/retina_trt_fp16\n",
    "!mkdir model_repository/retina_trt_fp16/1\n",
    "!mkdir model_repository/arcface_trt_fp16\n",
    "!mkdir model_repository/arcface_trt_fp16/1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9909d6d3",
   "metadata": {},
   "source": [
    "### Retinaface: Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7056759",
   "metadata": {},
   "outputs": [],
   "source": [
    "! git clone https://github.com/SthPhoenix/InsightFace-REST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff2ed69",
   "metadata": {},
   "outputs": [],
   "source": [
    "cd InsightFace-REST/src"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb70fd7f",
   "metadata": {},
   "source": [
    "**Download the required Retinaface Model: https://github.com/deepinsight/insightface/wiki/Model-Zoo**\n",
    "\n",
    "**Modification**\n",
    "\n",
    "- build_retina_trt.py to add \n",
    "   >model_dir, model_name, im_size [640, 480] (W, H)>\n",
    "\n",
    "**ONNX Conversion**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e0bc2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "! python converters/build_retina_trt.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0745a292",
   "metadata": {},
   "source": [
    "**TRT Conversion**\n",
    "\n",
    "- Ignore .plan file generated from above python scripsts\n",
    "- Consider .onnx or .onnx.tmp file for TRT conversion\n",
    "#(B, C, H, W )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732ebc5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!trtexec --onnx=/workspace/Courses/CV/inference/Bharat/FaceRecognition/insightface_onnx_trt_triton/models/onnx/retinaface_r50_v1/retinaface_r50_v1.onnx --saveEngine=/workspace/Courses/CV/inference/Bharat/FaceRecognition/insightface_onnx_trt_triton/model_repository/retina_trt_fp16/1/retinaface_r50_FP16.plan --fp16 --shapes=data:1x3x480x640 --minShapes=data:1x3x480x640 --optShapes=data:1x3x480x640 --maxShapes=data:32x3x480x640"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c5ee210",
   "metadata": {},
   "source": [
    "### Arcface: Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a5e09c",
   "metadata": {},
   "source": [
    "**Download the required Arcface Model: https://github.com/deepinsight/insightface/wiki/Model-Zoo**\n",
    "\n",
    "Example:- arcface_r100_v1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0701ad67",
   "metadata": {},
   "source": [
    "**Modification**\n",
    "\n",
    "- build_insight_trt.py to add \n",
    "    >model_dir, model_name, im_size [112, 112]\n",
    "\n",
    "**ONNX Conversion**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671490fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python converters/build_insight_trt.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a64c5d4",
   "metadata": {},
   "source": [
    "**TRT Conversion**\n",
    "\n",
    "- Ignore .plan file generated from above python scripts\n",
    "- Consider .onnx or .onnx.tmp file for TRT conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b85c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!trtexec --onnx=/workspace/Courses/CV/inference/Bharat/FaceRecognition/insightface_onnx_trt_triton/models/onnx/arcface_r100_v1/arcface_r100_v1.onnx --saveEngine=/workspace/Courses/CV/inference/Bharat/FaceRecognition/insightface_onnx_trt_triton/model_repository/arcface_trt_fp16/1/arcface_r100_v1_FP16.plan --fp16 --shapes=data:1x3x112x112 --minShapes=data:1x3x112x112 --optShapes=data:1x3x112x112 --maxShapes=data:32x3x112x112"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014889bd",
   "metadata": {},
   "source": [
    "# Save Final model models in a \"model_repository\"\n",
    "\n",
    "### model_repository\n",
    "\n",
    "```\n",
    "  model_repository/\n",
    "    arcface_trt_fp16/\n",
    "      1/\n",
    "        arcface_fp16.plan\n",
    "    retina_trt_fp16/\n",
    "      1/\n",
    "        retinaface_fp16.plan\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e511e1c8-3fe6-44e5-849a-2c03bc1af7fa",
   "metadata": {},
   "source": [
    "### Note: You can create fp32 tensorrt model as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "337cf30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf `find -type d -name .ipynb_checkpoints`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e676fd",
   "metadata": {},
   "source": [
    "### Run Triton Server\n",
    "docker run --gpus device=2 --net=host -v /home/path/to/model_repository/:/models --ipc=host  nvcr.io/nvidia/tritonserver:20.12-py3 tritonserver --model-repository=/models --strict-model-config=False --log-verbose=2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9586caa0",
   "metadata": {},
   "source": [
    "### Run Triton Server Cliednt SDK\n",
    "docker run -it -v /home/path/:/workspace/data --net=host nvcr.io/nvidia/tritonserver:20.12-py3-sdk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a129f4b4-20a2-4497-8984-840f0d0dc0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -v localhost:8000/v2/models/arcface_trt_fp16/config "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83309435-bcfb-41c9-8705-c0b7eff9efad",
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -v localhost:8000/v2/models/retina_trt_fp16/config "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd0e19fc-99a0-46f4-b5da-6a6233fdd418",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Measurement Settings ***\n",
      "  Batch size: 1\n",
      "  Measurement window: 5000 msec\n",
      "  Using synchronous calls for inference\n",
      "  Stabilizing using average latency\n",
      "\n",
      "Request concurrency: 1\n",
      "  Client: \n",
      "    Request count: 2008\n",
      "    Throughput: 401.6 infer/sec\n",
      "    Avg latency: 2489 usec (standard deviation 1021 usec)\n",
      "    p50 latency: 2449 usec\n",
      "    p90 latency: 2481 usec\n",
      "    p95 latency: 2499 usec\n",
      "    p99 latency: 2770 usec\n",
      "    Avg gRPC time: 2463 usec ((un)marshal request/response 25 usec + response wait 2438 usec)\n",
      "  Server: \n",
      "    Inference count: 2423\n",
      "    Execution count: 2423\n",
      "    Successful request count: 2423\n",
      "    Avg request latency: 1925 usec (overhead 1 usec + queue 19 usec + compute input 985 usec + compute infer 910 usec + compute output 10 usec)\n",
      "\n",
      "Inferences/Second vs. Client Average Batch Latency\n",
      "Concurrency: 1, throughput: 401.6 infer/sec, latency 2489 usec\n"
     ]
    }
   ],
   "source": [
    "!perf_analyzer -m arcface_trt_fp16 -b 1 -u localhost:8001 -i grpc --concurrency-range 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2af0254-23d4-4180-8e47-8b8c52ae9425",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Measurement Settings ***\n",
      "  Batch size: 1\n",
      "  Measurement window: 5000 msec\n",
      "  Using synchronous calls for inference\n",
      "  Stabilizing using average latency\n",
      "\n",
      "Request concurrency: 1\n",
      "  Client: \n",
      "    Request count: 482\n",
      "    Throughput: 96.4 infer/sec\n",
      "    Avg latency: 10357 usec (standard deviation 2244 usec)\n",
      "    p50 latency: 9983 usec\n",
      "    p90 latency: 11858 usec\n",
      "    p95 latency: 12124 usec\n",
      "    p99 latency: 12567 usec\n",
      "    Avg gRPC time: 10279 usec ((un)marshal request/response 583 usec + response wait 9696 usec)\n",
      "  Server: \n",
      "    Inference count: 578\n",
      "    Execution count: 578\n",
      "    Successful request count: 578\n",
      "    Avg request latency: 4814 usec (overhead 3 usec + queue 22 usec + compute input 2237 usec + compute infer 2288 usec + compute output 264 usec)\n",
      "\n",
      "Inferences/Second vs. Client Average Batch Latency\n",
      "Concurrency: 1, throughput: 96.4 infer/sec, latency 10357 usec\n"
     ]
    }
   ],
   "source": [
    "!perf_analyzer -m retina_trt_fp16 -b 1 -u localhost:8001 -i grpc --concurrency-range 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
