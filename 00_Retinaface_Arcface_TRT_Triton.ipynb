{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### nvcr.io/nvidia/pytorch:20.12-py3   [Will vary if Jetson]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! git clone https://github.com/biubug6/Pytorch_Retinaface.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'Pytorch_Retinaface'\n",
      "/workspace/Courses/CV/inference/Bharat/FaceRecognition/pyt_retinaface_arcface/Pytorch_Retinaface\n"
     ]
    }
   ],
   "source": [
    "cd Pytorch_Retinaface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retinaface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download Resnet50_Final.pth from https://drive.google.com/drive/folders/1oZRSG0ZegbVkVwUd8wUIQx8W7yfZ_ki1 in \"weights\" direactory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘model_repository’: File exists\n"
     ]
    }
   ],
   "source": [
    "! mkdir model_repository\n",
    "! mkdir model_repository/onnx_retina\n",
    "! mkdir model_repository/onnx_retina/1\n",
    "! mkdir model_repository/trt_fp32_retina\n",
    "! mkdir model_repository/trt_fp32_retina/1\n",
    "! mkdir model_repository/trt_fp16_retina\n",
    "! mkdir model_repository/trt_fp16_retina/1\n",
    "! mkdir model_repository/onnx_arc\n",
    "! mkdir model_repository/onnx_arc/1\n",
    "! mkdir model_repository/trt_fp32_arc\n",
    "! mkdir model_repository/trt_fp32_arc/1\n",
    "! mkdir model_repository/trt_fp16_arc\n",
    "! mkdir model_repository/trt_fp16_arc/1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Replace convert_to_onnx.py with the attached file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pretrained model from ./weights/Resnet50_Final.pth\n",
      "remove prefix 'module.'\n",
      "Missing keys:0\n",
      "Unused checkpoint keys:0\n",
      "Used keys:456\n",
      "Finished loading model!\n",
      "RetinaFace(\n",
      "  (body): IntermediateLayerGetter(\n",
      "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    (layer1): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (layer2): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (3): Bottleneck(\n",
      "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (layer3): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (3): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (4): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (5): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (layer4): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (fpn): FPN(\n",
      "    (output1): Sequential(\n",
      "      (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): LeakyReLU(negative_slope=0, inplace=True)\n",
      "    )\n",
      "    (output2): Sequential(\n",
      "      (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): LeakyReLU(negative_slope=0, inplace=True)\n",
      "    )\n",
      "    (output3): Sequential(\n",
      "      (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): LeakyReLU(negative_slope=0, inplace=True)\n",
      "    )\n",
      "    (merge1): Sequential(\n",
      "      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): LeakyReLU(negative_slope=0, inplace=True)\n",
      "    )\n",
      "    (merge2): Sequential(\n",
      "      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): LeakyReLU(negative_slope=0, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (ssh1): SSH(\n",
      "    (conv3X3): Sequential(\n",
      "      (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (conv5X5_1): Sequential(\n",
      "      (0): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): LeakyReLU(negative_slope=0, inplace=True)\n",
      "    )\n",
      "    (conv5X5_2): Sequential(\n",
      "      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (conv7X7_2): Sequential(\n",
      "      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): LeakyReLU(negative_slope=0, inplace=True)\n",
      "    )\n",
      "    (conv7x7_3): Sequential(\n",
      "      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (ssh2): SSH(\n",
      "    (conv3X3): Sequential(\n",
      "      (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (conv5X5_1): Sequential(\n",
      "      (0): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): LeakyReLU(negative_slope=0, inplace=True)\n",
      "    )\n",
      "    (conv5X5_2): Sequential(\n",
      "      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (conv7X7_2): Sequential(\n",
      "      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): LeakyReLU(negative_slope=0, inplace=True)\n",
      "    )\n",
      "    (conv7x7_3): Sequential(\n",
      "      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (ssh3): SSH(\n",
      "    (conv3X3): Sequential(\n",
      "      (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (conv5X5_1): Sequential(\n",
      "      (0): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): LeakyReLU(negative_slope=0, inplace=True)\n",
      "    )\n",
      "    (conv5X5_2): Sequential(\n",
      "      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (conv7X7_2): Sequential(\n",
      "      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): LeakyReLU(negative_slope=0, inplace=True)\n",
      "    )\n",
      "    (conv7x7_3): Sequential(\n",
      "      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (ClassHead): ModuleList(\n",
      "    (0): ClassHead(\n",
      "      (conv1x1): Conv2d(256, 4, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (1): ClassHead(\n",
      "      (conv1x1): Conv2d(256, 4, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (2): ClassHead(\n",
      "      (conv1x1): Conv2d(256, 4, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      "  (BboxHead): ModuleList(\n",
      "    (0): BboxHead(\n",
      "      (conv1x1): Conv2d(256, 8, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (1): BboxHead(\n",
      "      (conv1x1): Conv2d(256, 8, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (2): BboxHead(\n",
      "      (conv1x1): Conv2d(256, 8, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      "  (LandmarkHead): ModuleList(\n",
      "    (0): LandmarkHead(\n",
      "      (conv1x1): Conv2d(256, 20, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (1): LandmarkHead(\n",
      "      (conv1x1): Conv2d(256, 20, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (2): LandmarkHead(\n",
      "      (conv1x1): Conv2d(256, 20, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "cuda\n",
      "==> Exporting model to ONNX format at 'model_repository/onnx_retina/1/model.onnx'\n"
     ]
    }
   ],
   "source": [
    "! python convert_to_onnx.py --network=resnet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "&&&& RUNNING TensorRT.trtexec # trtexec --onnx=model_repository/onnx_retina/1/model.onnx --explicitBatch --optShapes=input0:8x3x640x640 --maxShapes=input0:64x3x640x640 --minShapes=input0:1x3x640x640 --saveEngine=model_repository/trt_fp32_retina/1/trt_fp32_retinaface.plan\n",
      "[06/04/2021-09:51:52] [I] === Model Options ===\n",
      "[06/04/2021-09:51:52] [I] Format: ONNX\n",
      "[06/04/2021-09:51:52] [I] Model: model_repository/onnx_retina/1/model.onnx\n",
      "[06/04/2021-09:51:52] [I] Output:\n",
      "[06/04/2021-09:51:52] [I] === Build Options ===\n",
      "[06/04/2021-09:51:52] [I] Max batch: explicit\n",
      "[06/04/2021-09:51:52] [I] Workspace: 16 MiB\n",
      "[06/04/2021-09:51:52] [I] minTiming: 1\n",
      "[06/04/2021-09:51:52] [I] avgTiming: 8\n",
      "[06/04/2021-09:51:52] [I] Precision: FP32\n",
      "[06/04/2021-09:51:52] [I] Calibration: \n",
      "[06/04/2021-09:51:52] [I] Refit: Disabled\n",
      "[06/04/2021-09:51:52] [I] Safe mode: Disabled\n",
      "[06/04/2021-09:51:52] [I] Save engine: model_repository/trt_fp32_retina/1/trt_fp32_retinaface.plan\n",
      "[06/04/2021-09:51:52] [I] Load engine: \n",
      "[06/04/2021-09:51:52] [I] Builder Cache: Enabled\n",
      "[06/04/2021-09:51:52] [I] NVTX verbosity: 0\n",
      "[06/04/2021-09:51:52] [I] Tactic sources: Using default tactic sources\n",
      "[06/04/2021-09:51:52] [I] Input(s)s format: fp32:CHW\n",
      "[06/04/2021-09:51:52] [I] Output(s)s format: fp32:CHW\n",
      "[06/04/2021-09:51:52] [I] Input build shape: input0=1x3x640x640+8x3x640x640+64x3x640x640\n",
      "[06/04/2021-09:51:52] [I] Input calibration shapes: model\n",
      "[06/04/2021-09:51:52] [I] === System Options ===\n",
      "[06/04/2021-09:51:52] [I] Device: 0\n",
      "[06/04/2021-09:51:52] [I] DLACore: \n",
      "[06/04/2021-09:51:52] [I] Plugins:\n",
      "[06/04/2021-09:51:52] [I] === Inference Options ===\n",
      "[06/04/2021-09:51:52] [I] Batch: Explicit\n",
      "[06/04/2021-09:51:52] [I] Input inference shape: input0=8x3x640x640\n",
      "[06/04/2021-09:51:52] [I] Iterations: 10\n",
      "[06/04/2021-09:51:52] [I] Duration: 3s (+ 200ms warm up)\n",
      "[06/04/2021-09:51:52] [I] Sleep time: 0ms\n",
      "[06/04/2021-09:51:52] [I] Streams: 1\n",
      "[06/04/2021-09:51:52] [I] ExposeDMA: Disabled\n",
      "[06/04/2021-09:51:52] [I] Data transfers: Enabled\n",
      "[06/04/2021-09:51:52] [I] Spin-wait: Disabled\n",
      "[06/04/2021-09:51:52] [I] Multithreading: Disabled\n",
      "[06/04/2021-09:51:52] [I] CUDA Graph: Disabled\n",
      "[06/04/2021-09:51:52] [I] Separate profiling: Disabled\n",
      "[06/04/2021-09:51:52] [I] Skip inference: Disabled\n",
      "[06/04/2021-09:51:52] [I] Inputs:\n",
      "[06/04/2021-09:51:52] [I] === Reporting Options ===\n",
      "[06/04/2021-09:51:52] [I] Verbose: Disabled\n",
      "[06/04/2021-09:51:52] [I] Averages: 10 inferences\n",
      "[06/04/2021-09:51:52] [I] Percentile: 99\n",
      "[06/04/2021-09:51:52] [I] Dump refittable layers:Disabled\n",
      "[06/04/2021-09:51:52] [I] Dump output: Disabled\n",
      "[06/04/2021-09:51:52] [I] Profile: Disabled\n",
      "[06/04/2021-09:51:52] [I] Export timing to JSON file: \n",
      "[06/04/2021-09:51:52] [I] Export output to JSON file: \n",
      "[06/04/2021-09:51:52] [I] Export profile to JSON file: \n",
      "[06/04/2021-09:51:52] [I] \n",
      "[06/04/2021-09:51:52] [I] === Device Information ===\n",
      "[06/04/2021-09:51:52] [I] Selected Device: Tesla V100-DGXS-32GB\n",
      "[06/04/2021-09:51:52] [I] Compute Capability: 7.0\n",
      "[06/04/2021-09:51:52] [I] SMs: 80\n",
      "[06/04/2021-09:51:52] [I] Compute Clock Rate: 1.53 GHz\n",
      "[06/04/2021-09:51:52] [I] Device Global Memory: 32478 MiB\n",
      "[06/04/2021-09:51:52] [I] Shared Memory per SM: 96 KiB\n",
      "[06/04/2021-09:51:52] [I] Memory Bus Width: 4096 bits (ECC enabled)\n",
      "[06/04/2021-09:51:52] [I] Memory Clock Rate: 0.877 GHz\n",
      "[06/04/2021-09:51:52] [I] \n",
      "----------------------------------------------------------------\n",
      "Input filename:   model_repository/onnx_retina/1/model.onnx\n",
      "ONNX IR version:  0.0.6\n",
      "Opset version:    11\n",
      "Producer name:    pytorch\n",
      "Producer version: 1.8\n",
      "Domain:           \n",
      "Model version:    0\n",
      "Doc string:       \n",
      "----------------------------------------------------------------\n",
      "[06/04/2021-09:52:08] [W] [TRT] /workspace/TensorRT/parsers/onnx/onnx2trt_utils.cpp:218: Your ONNX model has been generated with INT64 weights, while TensorRT does not natively support INT64. Attempting to cast down to INT32.\n",
      "[06/04/2021-09:52:10] [I] [TRT] Some tactics do not have sufficient workspace memory to run. Increasing workspace size may increase performance, please check verbose output.\n",
      "[06/04/2021-09:53:17] [I] [TRT] Detected 1 inputs and 9 output network tensors.\n",
      "[06/04/2021-09:53:19] [I] Engine built in 86.4059 sec.\n",
      "[06/04/2021-09:53:19] [I] Starting inference\n",
      "[06/04/2021-09:53:22] [I] Warmup completed 0 queries over 200 ms\n",
      "[06/04/2021-09:53:22] [I] Timing trace has 0 queries over 3.13357 s\n",
      "[06/04/2021-09:53:22] [I] Trace averages of 10 runs:\n",
      "[06/04/2021-09:53:22] [I] Average on 10 runs - GPU latency: 48.0175 ms - Host latency: 52.149 ms (end to end 95.6774 ms, enqueue 1.21542 ms)\n",
      "[06/04/2021-09:53:22] [I] Average on 10 runs - GPU latency: 47.2724 ms - Host latency: 51.4117 ms (end to end 94.4798 ms, enqueue 1.1908 ms)\n",
      "[06/04/2021-09:53:22] [I] Average on 10 runs - GPU latency: 47.3328 ms - Host latency: 51.4642 ms (end to end 91.4075 ms, enqueue 1.15929 ms)\n",
      "[06/04/2021-09:53:22] [I] Average on 10 runs - GPU latency: 47.2933 ms - Host latency: 51.4306 ms (end to end 93.4893 ms, enqueue 1.16591 ms)\n",
      "[06/04/2021-09:53:22] [I] Average on 10 runs - GPU latency: 47.4247 ms - Host latency: 51.5599 ms (end to end 94.2797 ms, enqueue 1.14954 ms)\n",
      "[06/04/2021-09:53:22] [I] Average on 10 runs - GPU latency: 47.3962 ms - Host latency: 51.5375 ms (end to end 94.3861 ms, enqueue 1.17305 ms)\n",
      "[06/04/2021-09:53:22] [I] Host Latency\n",
      "[06/04/2021-09:53:22] [I] min: 51.0469 ms (end to end 68.9719 ms)\n",
      "[06/04/2021-09:53:22] [I] max: 52.8431 ms (end to end 97.1636 ms)\n",
      "[06/04/2021-09:53:22] [I] mean: 51.5967 ms (end to end 93.9091 ms)\n",
      "[06/04/2021-09:53:22] [I] median: 51.5601 ms (end to end 94.6509 ms)\n",
      "[06/04/2021-09:53:22] [I] percentile: 52.8431 ms at 99% (end to end 97.1636 ms at 99%)\n",
      "[06/04/2021-09:53:22] [I] throughput: 0 qps\n",
      "[06/04/2021-09:53:22] [I] walltime: 3.13357 s\n",
      "[06/04/2021-09:53:22] [I] Enqueue Time\n",
      "[06/04/2021-09:53:22] [I] min: 0.988037 ms\n",
      "[06/04/2021-09:53:22] [I] max: 1.54907 ms\n",
      "[06/04/2021-09:53:22] [I] median: 1.17975 ms\n",
      "[06/04/2021-09:53:22] [I] GPU Compute\n",
      "[06/04/2021-09:53:22] [I] min: 46.9136 ms\n",
      "[06/04/2021-09:53:22] [I] max: 48.7178 ms\n",
      "[06/04/2021-09:53:22] [I] mean: 47.46 ms\n",
      "[06/04/2021-09:53:22] [I] median: 47.4297 ms\n",
      "[06/04/2021-09:53:22] [I] percentile: 48.7178 ms at 99%\n",
      "[06/04/2021-09:53:22] [I] total compute time: 3.0849 s\n",
      "&&&& PASSED TensorRT.trtexec # trtexec --onnx=model_repository/onnx_retina/1/model.onnx --explicitBatch --optShapes=input0:8x3x640x640 --maxShapes=input0:64x3x640x640 --minShapes=input0:1x3x640x640 --saveEngine=model_repository/trt_fp32_retina/1/trt_fp32_retinaface.plan\n"
     ]
    }
   ],
   "source": [
    "! trtexec --onnx=model_repository/onnx_retina/1/model.onnx --explicitBatch --optShapes=input0:8x3x640x640 --maxShapes=input0:64x3x640x640 --minShapes=input0:1x3x640x640 --saveEngine=model_repository/trt_fp32_retina/1/trt_fp32_retinaface.plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "&&&& RUNNING TensorRT.trtexec # trtexec --onnx=model_repository/onnx_retina/1/model.onnx --explicitBatch --optShapes=input0:8x3x640x640 --maxShapes=input0:64x3x640x640 --minShapes=input0:1x3x640x640 --saveEngine=model_repository/trt_fp16_retina/1/trt_fp16_retinaface.plan --fp16\n",
      "[06/04/2021-09:53:24] [I] === Model Options ===\n",
      "[06/04/2021-09:53:24] [I] Format: ONNX\n",
      "[06/04/2021-09:53:24] [I] Model: model_repository/onnx_retina/1/model.onnx\n",
      "[06/04/2021-09:53:24] [I] Output:\n",
      "[06/04/2021-09:53:24] [I] === Build Options ===\n",
      "[06/04/2021-09:53:24] [I] Max batch: explicit\n",
      "[06/04/2021-09:53:24] [I] Workspace: 16 MiB\n",
      "[06/04/2021-09:53:24] [I] minTiming: 1\n",
      "[06/04/2021-09:53:24] [I] avgTiming: 8\n",
      "[06/04/2021-09:53:24] [I] Precision: FP32+FP16\n",
      "[06/04/2021-09:53:24] [I] Calibration: \n",
      "[06/04/2021-09:53:24] [I] Refit: Disabled\n",
      "[06/04/2021-09:53:24] [I] Safe mode: Disabled\n",
      "[06/04/2021-09:53:24] [I] Save engine: model_repository/trt_fp16_retina/1/trt_fp16_retinaface.plan\n",
      "[06/04/2021-09:53:24] [I] Load engine: \n",
      "[06/04/2021-09:53:24] [I] Builder Cache: Enabled\n",
      "[06/04/2021-09:53:24] [I] NVTX verbosity: 0\n",
      "[06/04/2021-09:53:24] [I] Tactic sources: Using default tactic sources\n",
      "[06/04/2021-09:53:24] [I] Input(s)s format: fp32:CHW\n",
      "[06/04/2021-09:53:24] [I] Output(s)s format: fp32:CHW\n",
      "[06/04/2021-09:53:24] [I] Input build shape: input0=1x3x640x640+8x3x640x640+64x3x640x640\n",
      "[06/04/2021-09:53:24] [I] Input calibration shapes: model\n",
      "[06/04/2021-09:53:24] [I] === System Options ===\n",
      "[06/04/2021-09:53:24] [I] Device: 0\n",
      "[06/04/2021-09:53:24] [I] DLACore: \n",
      "[06/04/2021-09:53:24] [I] Plugins:\n",
      "[06/04/2021-09:53:24] [I] === Inference Options ===\n",
      "[06/04/2021-09:53:24] [I] Batch: Explicit\n",
      "[06/04/2021-09:53:24] [I] Input inference shape: input0=8x3x640x640\n",
      "[06/04/2021-09:53:24] [I] Iterations: 10\n",
      "[06/04/2021-09:53:24] [I] Duration: 3s (+ 200ms warm up)\n",
      "[06/04/2021-09:53:24] [I] Sleep time: 0ms\n",
      "[06/04/2021-09:53:24] [I] Streams: 1\n",
      "[06/04/2021-09:53:24] [I] ExposeDMA: Disabled\n",
      "[06/04/2021-09:53:24] [I] Data transfers: Enabled\n",
      "[06/04/2021-09:53:24] [I] Spin-wait: Disabled\n",
      "[06/04/2021-09:53:24] [I] Multithreading: Disabled\n",
      "[06/04/2021-09:53:24] [I] CUDA Graph: Disabled\n",
      "[06/04/2021-09:53:24] [I] Separate profiling: Disabled\n",
      "[06/04/2021-09:53:24] [I] Skip inference: Disabled\n",
      "[06/04/2021-09:53:24] [I] Inputs:\n",
      "[06/04/2021-09:53:24] [I] === Reporting Options ===\n",
      "[06/04/2021-09:53:24] [I] Verbose: Disabled\n",
      "[06/04/2021-09:53:24] [I] Averages: 10 inferences\n",
      "[06/04/2021-09:53:24] [I] Percentile: 99\n",
      "[06/04/2021-09:53:24] [I] Dump refittable layers:Disabled\n",
      "[06/04/2021-09:53:24] [I] Dump output: Disabled\n",
      "[06/04/2021-09:53:24] [I] Profile: Disabled\n",
      "[06/04/2021-09:53:24] [I] Export timing to JSON file: \n",
      "[06/04/2021-09:53:24] [I] Export output to JSON file: \n",
      "[06/04/2021-09:53:24] [I] Export profile to JSON file: \n",
      "[06/04/2021-09:53:24] [I] \n",
      "[06/04/2021-09:53:24] [I] === Device Information ===\n",
      "[06/04/2021-09:53:24] [I] Selected Device: Tesla V100-DGXS-32GB\n",
      "[06/04/2021-09:53:24] [I] Compute Capability: 7.0\n",
      "[06/04/2021-09:53:24] [I] SMs: 80\n",
      "[06/04/2021-09:53:24] [I] Compute Clock Rate: 1.53 GHz\n",
      "[06/04/2021-09:53:24] [I] Device Global Memory: 32478 MiB\n",
      "[06/04/2021-09:53:24] [I] Shared Memory per SM: 96 KiB\n",
      "[06/04/2021-09:53:24] [I] Memory Bus Width: 4096 bits (ECC enabled)\n",
      "[06/04/2021-09:53:24] [I] Memory Clock Rate: 0.877 GHz\n",
      "[06/04/2021-09:53:24] [I] \n",
      "----------------------------------------------------------------\n",
      "Input filename:   model_repository/onnx_retina/1/model.onnx\n",
      "ONNX IR version:  0.0.6\n",
      "Opset version:    11\n",
      "Producer name:    pytorch\n",
      "Producer version: 1.8\n",
      "Domain:           \n",
      "Model version:    0\n",
      "Doc string:       \n",
      "----------------------------------------------------------------\n",
      "[06/04/2021-09:53:39] [W] [TRT] /workspace/TensorRT/parsers/onnx/onnx2trt_utils.cpp:218: Your ONNX model has been generated with INT64 weights, while TensorRT does not natively support INT64. Attempting to cast down to INT32.\n",
      "[06/04/2021-09:53:42] [I] [TRT] Some tactics do not have sufficient workspace memory to run. Increasing workspace size may increase performance, please check verbose output.\n",
      "[06/04/2021-09:56:35] [I] [TRT] Detected 1 inputs and 9 output network tensors.\n",
      "[06/04/2021-09:56:36] [I] Engine built in 192.061 sec.\n",
      "[06/04/2021-09:56:36] [I] Starting inference\n",
      "[06/04/2021-09:56:39] [I] Warmup completed 0 queries over 200 ms\n",
      "[06/04/2021-09:56:39] [I] Timing trace has 0 queries over 3.03729 s\n",
      "[06/04/2021-09:56:39] [I] Trace averages of 10 runs:\n",
      "[06/04/2021-09:56:39] [I] Average on 10 runs - GPU latency: 13.4066 ms - Host latency: 17.4222 ms (end to end 26.7101 ms, enqueue 1.03547 ms)\n",
      "[06/04/2021-09:56:39] [I] Average on 10 runs - GPU latency: 13.462 ms - Host latency: 17.4764 ms (end to end 26.5196 ms, enqueue 1.01119 ms)\n",
      "[06/04/2021-09:56:39] [I] Average on 10 runs - GPU latency: 13.353 ms - Host latency: 17.38 ms (end to end 25.8901 ms, enqueue 1.01317 ms)\n",
      "[06/04/2021-09:56:39] [I] Average on 10 runs - GPU latency: 13.2667 ms - Host latency: 17.3075 ms (end to end 25.4825 ms, enqueue 1.0096 ms)\n",
      "[06/04/2021-09:56:39] [I] Average on 10 runs - GPU latency: 13.1864 ms - Host latency: 17.2929 ms (end to end 26.2802 ms, enqueue 1.02133 ms)\n",
      "[06/04/2021-09:56:39] [I] Average on 10 runs - GPU latency: 13.1734 ms - Host latency: 17.2918 ms (end to end 25.8014 ms, enqueue 1.02057 ms)\n",
      "[06/04/2021-09:56:39] [I] Average on 10 runs - GPU latency: 13.2294 ms - Host latency: 17.3385 ms (end to end 26.3145 ms, enqueue 1.01407 ms)\n",
      "[06/04/2021-09:56:39] [I] Average on 10 runs - GPU latency: 13.2047 ms - Host latency: 17.3221 ms (end to end 25.8003 ms, enqueue 1.01997 ms)\n",
      "[06/04/2021-09:56:39] [I] Average on 10 runs - GPU latency: 13.1664 ms - Host latency: 17.2843 ms (end to end 26.2332 ms, enqueue 1.01528 ms)\n",
      "[06/04/2021-09:56:39] [I] Average on 10 runs - GPU latency: 13.1926 ms - Host latency: 17.3001 ms (end to end 25.8693 ms, enqueue 0.996631 ms)\n",
      "[06/04/2021-09:56:39] [I] Average on 10 runs - GPU latency: 13.2129 ms - Host latency: 17.3329 ms (end to end 26.34 ms, enqueue 1.00887 ms)\n",
      "[06/04/2021-09:56:39] [I] Average on 10 runs - GPU latency: 13.2184 ms - Host latency: 17.3464 ms (end to end 25.8131 ms, enqueue 1.02126 ms)\n",
      "[06/04/2021-09:56:39] [I] Average on 10 runs - GPU latency: 13.1711 ms - Host latency: 17.2993 ms (end to end 26.2509 ms, enqueue 1.02512 ms)\n",
      "[06/04/2021-09:56:39] [I] Average on 10 runs - GPU latency: 13.2346 ms - Host latency: 17.3606 ms (end to end 25.6757 ms, enqueue 1.01267 ms)\n",
      "[06/04/2021-09:56:39] [I] Average on 10 runs - GPU latency: 13.2111 ms - Host latency: 17.3305 ms (end to end 26.115 ms, enqueue 1.0101 ms)\n",
      "[06/04/2021-09:56:39] [I] Average on 10 runs - GPU latency: 13.2287 ms - Host latency: 17.382 ms (end to end 24.2432 ms, enqueue 0.993213 ms)\n",
      "[06/04/2021-09:56:39] [I] Average on 10 runs - GPU latency: 13.2309 ms - Host latency: 17.355 ms (end to end 25.5299 ms, enqueue 1.00134 ms)\n",
      "[06/04/2021-09:56:39] [I] Average on 10 runs - GPU latency: 13.223 ms - Host latency: 17.3435 ms (end to end 25.8768 ms, enqueue 1.00891 ms)\n",
      "[06/04/2021-09:56:39] [I] Average on 10 runs - GPU latency: 13.2042 ms - Host latency: 17.3391 ms (end to end 26.1533 ms, enqueue 1.07976 ms)\n",
      "[06/04/2021-09:56:39] [I] Average on 10 runs - GPU latency: 13.2203 ms - Host latency: 17.3465 ms (end to end 26.3392 ms, enqueue 0.939185 ms)\n",
      "[06/04/2021-09:56:39] [I] Average on 10 runs - GPU latency: 13.2451 ms - Host latency: 17.3758 ms (end to end 25.9473 ms, enqueue 0.919067 ms)\n",
      "[06/04/2021-09:56:39] [I] Average on 10 runs - GPU latency: 13.2269 ms - Host latency: 17.3487 ms (end to end 25.9676 ms, enqueue 0.926489 ms)\n",
      "[06/04/2021-09:56:39] [I] Host Latency\n",
      "[06/04/2021-09:56:39] [I] min: 17.2349 ms (end to end 17.3335 ms)\n",
      "[06/04/2021-09:56:39] [I] max: 17.594 ms (end to end 27.1702 ms)\n",
      "[06/04/2021-09:56:39] [I] mean: 17.3438 ms (end to end 25.9364 ms)\n",
      "[06/04/2021-09:56:39] [I] median: 17.3382 ms (end to end 26.3127 ms)\n",
      "[06/04/2021-09:56:39] [I] percentile: 17.5279 ms at 99% (end to end 26.8759 ms at 99%)\n",
      "[06/04/2021-09:56:39] [I] throughput: 0 qps\n",
      "[06/04/2021-09:56:39] [I] walltime: 3.03729 s\n",
      "[06/04/2021-09:56:39] [I] Enqueue Time\n",
      "[06/04/2021-09:56:39] [I] min: 0.809082 ms\n",
      "[06/04/2021-09:56:39] [I] max: 1.37085 ms\n",
      "[06/04/2021-09:56:39] [I] median: 1.01105 ms\n",
      "[06/04/2021-09:56:39] [I] GPU Compute\n",
      "[06/04/2021-09:56:39] [I] min: 13.1226 ms\n",
      "[06/04/2021-09:56:39] [I] max: 13.5056 ms\n",
      "[06/04/2021-09:56:39] [I] mean: 13.2382 ms\n",
      "[06/04/2021-09:56:39] [I] median: 13.2183 ms\n",
      "[06/04/2021-09:56:39] [I] percentile: 13.4922 ms at 99%\n",
      "[06/04/2021-09:56:39] [I] total compute time: 3.01831 s\n",
      "&&&& PASSED TensorRT.trtexec # trtexec --onnx=model_repository/onnx_retina/1/model.onnx --explicitBatch --optShapes=input0:8x3x640x640 --maxShapes=input0:64x3x640x640 --minShapes=input0:1x3x640x640 --saveEngine=model_repository/trt_fp16_retina/1/trt_fp16_retinaface.plan --fp16\n"
     ]
    }
   ],
   "source": [
    "! trtexec --onnx=model_repository/onnx_retina/1/model.onnx --explicitBatch --optShapes=input0:8x3x640x640 --maxShapes=input0:64x3x640x640 --minShapes=input0:1x3x640x640 --saveEngine=model_repository/trt_fp16_retina/1/trt_fp16_retinaface.plan --fp16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arcface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Input name and Dimension of Onnx model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download and store ONNX Model from https://github.com/onnx/models/blob/master/vision/body_analysis/arcface/model/arcfaceresnet100-8.onnx in directory **\"model_repository/onnx_arc/1\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data: 1, 3, 112, 112, \n",
      "scalar_op2: 1, \n",
      "scalar_op3: 1, \n",
      "conv0_weight: 64, 3, 3, 3, \n",
      "bn0_gamma: 64, \n",
      "bn0_beta: 64, \n",
      "bn0_moving_mean: 64, \n",
      "bn0_moving_var: 64, \n",
      "relu0_gamma: 64, \n",
      "reshape12: 4, \n",
      "stage1_unit1_bn1_gamma: 64, \n",
      "stage1_unit1_bn1_beta: 64, \n",
      "stage1_unit1_bn1_moving_mean: 64, \n",
      "stage1_unit1_bn1_moving_var: 64, \n",
      "stage1_unit1_conv1_weight: 64, 64, 3, 3, \n",
      "stage1_unit1_bn2_gamma: 64, \n",
      "stage1_unit1_bn2_beta: 64, \n",
      "stage1_unit1_bn2_moving_mean: 64, \n",
      "stage1_unit1_bn2_moving_var: 64, \n",
      "stage1_unit1_relu1_gamma: 64, \n",
      "reshape26: 4, \n",
      "stage1_unit1_conv2_weight: 64, 64, 3, 3, \n",
      "stage1_unit1_bn3_gamma: 64, \n",
      "stage1_unit1_bn3_beta: 64, \n",
      "stage1_unit1_bn3_moving_mean: 64, \n",
      "stage1_unit1_bn3_moving_var: 64, \n",
      "stage1_unit1_conv1sc_weight: 64, 64, 1, 1, \n",
      "stage1_unit1_sc_gamma: 64, \n",
      "stage1_unit1_sc_beta: 64, \n",
      "stage1_unit1_sc_moving_mean: 64, \n",
      "stage1_unit1_sc_moving_var: 64, \n",
      "stage1_unit2_bn1_gamma: 64, \n",
      "stage1_unit2_bn1_beta: 64, \n",
      "stage1_unit2_bn1_moving_mean: 64, \n",
      "stage1_unit2_bn1_moving_var: 64, \n",
      "stage1_unit2_conv1_weight: 64, 64, 3, 3, \n",
      "stage1_unit2_bn2_gamma: 64, \n",
      "stage1_unit2_bn2_beta: 64, \n",
      "stage1_unit2_bn2_moving_mean: 64, \n",
      "stage1_unit2_bn2_moving_var: 64, \n",
      "stage1_unit2_relu1_gamma: 64, \n",
      "reshape55: 4, \n",
      "stage1_unit2_conv2_weight: 64, 64, 3, 3, \n",
      "stage1_unit2_bn3_gamma: 64, \n",
      "stage1_unit2_bn3_beta: 64, \n",
      "stage1_unit2_bn3_moving_mean: 64, \n",
      "stage1_unit2_bn3_moving_var: 64, \n",
      "stage1_unit3_bn1_gamma: 64, \n",
      "stage1_unit3_bn1_beta: 64, \n",
      "stage1_unit3_bn1_moving_mean: 64, \n",
      "stage1_unit3_bn1_moving_var: 64, \n",
      "stage1_unit3_conv1_weight: 64, 64, 3, 3, \n",
      "stage1_unit3_bn2_gamma: 64, \n",
      "stage1_unit3_bn2_beta: 64, \n",
      "stage1_unit3_bn2_moving_mean: 64, \n",
      "stage1_unit3_bn2_moving_var: 64, \n",
      "stage1_unit3_relu1_gamma: 64, \n",
      "reshape77: 4, \n",
      "stage1_unit3_conv2_weight: 64, 64, 3, 3, \n",
      "stage1_unit3_bn3_gamma: 64, \n",
      "stage1_unit3_bn3_beta: 64, \n",
      "stage1_unit3_bn3_moving_mean: 64, \n",
      "stage1_unit3_bn3_moving_var: 64, \n",
      "stage2_unit1_bn1_gamma: 64, \n",
      "stage2_unit1_bn1_beta: 64, \n",
      "stage2_unit1_bn1_moving_mean: 64, \n",
      "stage2_unit1_bn1_moving_var: 64, \n",
      "stage2_unit1_conv1_weight: 128, 64, 3, 3, \n",
      "stage2_unit1_bn2_gamma: 128, \n",
      "stage2_unit1_bn2_beta: 128, \n",
      "stage2_unit1_bn2_moving_mean: 128, \n",
      "stage2_unit1_bn2_moving_var: 128, \n",
      "stage2_unit1_relu1_gamma: 128, \n",
      "reshape99: 4, \n",
      "stage2_unit1_conv2_weight: 128, 128, 3, 3, \n",
      "stage2_unit1_bn3_gamma: 128, \n",
      "stage2_unit1_bn3_beta: 128, \n",
      "stage2_unit1_bn3_moving_mean: 128, \n",
      "stage2_unit1_bn3_moving_var: 128, \n",
      "stage2_unit1_conv1sc_weight: 128, 64, 1, 1, \n",
      "stage2_unit1_sc_gamma: 128, \n",
      "stage2_unit1_sc_beta: 128, \n",
      "stage2_unit1_sc_moving_mean: 128, \n",
      "stage2_unit1_sc_moving_var: 128, \n",
      "stage2_unit2_bn1_gamma: 128, \n",
      "stage2_unit2_bn1_beta: 128, \n",
      "stage2_unit2_bn1_moving_mean: 128, \n",
      "stage2_unit2_bn1_moving_var: 128, \n",
      "stage2_unit2_conv1_weight: 128, 128, 3, 3, \n",
      "stage2_unit2_bn2_gamma: 128, \n",
      "stage2_unit2_bn2_beta: 128, \n",
      "stage2_unit2_bn2_moving_mean: 128, \n",
      "stage2_unit2_bn2_moving_var: 128, \n",
      "stage2_unit2_relu1_gamma: 128, \n",
      "reshape128: 4, \n",
      "stage2_unit2_conv2_weight: 128, 128, 3, 3, \n",
      "stage2_unit2_bn3_gamma: 128, \n",
      "stage2_unit2_bn3_beta: 128, \n",
      "stage2_unit2_bn3_moving_mean: 128, \n",
      "stage2_unit2_bn3_moving_var: 128, \n",
      "stage2_unit3_bn1_gamma: 128, \n",
      "stage2_unit3_bn1_beta: 128, \n",
      "stage2_unit3_bn1_moving_mean: 128, \n",
      "stage2_unit3_bn1_moving_var: 128, \n",
      "stage2_unit3_conv1_weight: 128, 128, 3, 3, \n",
      "stage2_unit3_bn2_gamma: 128, \n",
      "stage2_unit3_bn2_beta: 128, \n",
      "stage2_unit3_bn2_moving_mean: 128, \n",
      "stage2_unit3_bn2_moving_var: 128, \n",
      "stage2_unit3_relu1_gamma: 128, \n",
      "reshape150: 4, \n",
      "stage2_unit3_conv2_weight: 128, 128, 3, 3, \n",
      "stage2_unit3_bn3_gamma: 128, \n",
      "stage2_unit3_bn3_beta: 128, \n",
      "stage2_unit3_bn3_moving_mean: 128, \n",
      "stage2_unit3_bn3_moving_var: 128, \n",
      "stage2_unit4_bn1_gamma: 128, \n",
      "stage2_unit4_bn1_beta: 128, \n",
      "stage2_unit4_bn1_moving_mean: 128, \n",
      "stage2_unit4_bn1_moving_var: 128, \n",
      "stage2_unit4_conv1_weight: 128, 128, 3, 3, \n",
      "stage2_unit4_bn2_gamma: 128, \n",
      "stage2_unit4_bn2_beta: 128, \n",
      "stage2_unit4_bn2_moving_mean: 128, \n",
      "stage2_unit4_bn2_moving_var: 128, \n",
      "stage2_unit4_relu1_gamma: 128, \n",
      "reshape172: 4, \n",
      "stage2_unit4_conv2_weight: 128, 128, 3, 3, \n",
      "stage2_unit4_bn3_gamma: 128, \n",
      "stage2_unit4_bn3_beta: 128, \n",
      "stage2_unit4_bn3_moving_mean: 128, \n",
      "stage2_unit4_bn3_moving_var: 128, \n",
      "stage2_unit5_bn1_gamma: 128, \n",
      "stage2_unit5_bn1_beta: 128, \n",
      "stage2_unit5_bn1_moving_mean: 128, \n",
      "stage2_unit5_bn1_moving_var: 128, \n",
      "stage2_unit5_conv1_weight: 128, 128, 3, 3, \n",
      "stage2_unit5_bn2_gamma: 128, \n",
      "stage2_unit5_bn2_beta: 128, \n",
      "stage2_unit5_bn2_moving_mean: 128, \n",
      "stage2_unit5_bn2_moving_var: 128, \n",
      "stage2_unit5_relu1_gamma: 128, \n",
      "reshape194: 4, \n",
      "stage2_unit5_conv2_weight: 128, 128, 3, 3, \n",
      "stage2_unit5_bn3_gamma: 128, \n",
      "stage2_unit5_bn3_beta: 128, \n",
      "stage2_unit5_bn3_moving_mean: 128, \n",
      "stage2_unit5_bn3_moving_var: 128, \n",
      "stage2_unit6_bn1_gamma: 128, \n",
      "stage2_unit6_bn1_beta: 128, \n",
      "stage2_unit6_bn1_moving_mean: 128, \n",
      "stage2_unit6_bn1_moving_var: 128, \n",
      "stage2_unit6_conv1_weight: 128, 128, 3, 3, \n",
      "stage2_unit6_bn2_gamma: 128, \n",
      "stage2_unit6_bn2_beta: 128, \n",
      "stage2_unit6_bn2_moving_mean: 128, \n",
      "stage2_unit6_bn2_moving_var: 128, \n",
      "stage2_unit6_relu1_gamma: 128, \n",
      "reshape216: 4, \n",
      "stage2_unit6_conv2_weight: 128, 128, 3, 3, \n",
      "stage2_unit6_bn3_gamma: 128, \n",
      "stage2_unit6_bn3_beta: 128, \n",
      "stage2_unit6_bn3_moving_mean: 128, \n",
      "stage2_unit6_bn3_moving_var: 128, \n",
      "stage2_unit7_bn1_gamma: 128, \n",
      "stage2_unit7_bn1_beta: 128, \n",
      "stage2_unit7_bn1_moving_mean: 128, \n",
      "stage2_unit7_bn1_moving_var: 128, \n",
      "stage2_unit7_conv1_weight: 128, 128, 3, 3, \n",
      "stage2_unit7_bn2_gamma: 128, \n",
      "stage2_unit7_bn2_beta: 128, \n",
      "stage2_unit7_bn2_moving_mean: 128, \n",
      "stage2_unit7_bn2_moving_var: 128, \n",
      "stage2_unit7_relu1_gamma: 128, \n",
      "reshape238: 4, \n",
      "stage2_unit7_conv2_weight: 128, 128, 3, 3, \n",
      "stage2_unit7_bn3_gamma: 128, \n",
      "stage2_unit7_bn3_beta: 128, \n",
      "stage2_unit7_bn3_moving_mean: 128, \n",
      "stage2_unit7_bn3_moving_var: 128, \n",
      "stage2_unit8_bn1_gamma: 128, \n",
      "stage2_unit8_bn1_beta: 128, \n",
      "stage2_unit8_bn1_moving_mean: 128, \n",
      "stage2_unit8_bn1_moving_var: 128, \n",
      "stage2_unit8_conv1_weight: 128, 128, 3, 3, \n",
      "stage2_unit8_bn2_gamma: 128, \n",
      "stage2_unit8_bn2_beta: 128, \n",
      "stage2_unit8_bn2_moving_mean: 128, \n",
      "stage2_unit8_bn2_moving_var: 128, \n",
      "stage2_unit8_relu1_gamma: 128, \n",
      "reshape260: 4, \n",
      "stage2_unit8_conv2_weight: 128, 128, 3, 3, \n",
      "stage2_unit8_bn3_gamma: 128, \n",
      "stage2_unit8_bn3_beta: 128, \n",
      "stage2_unit8_bn3_moving_mean: 128, \n",
      "stage2_unit8_bn3_moving_var: 128, \n",
      "stage2_unit9_bn1_gamma: 128, \n",
      "stage2_unit9_bn1_beta: 128, \n",
      "stage2_unit9_bn1_moving_mean: 128, \n",
      "stage2_unit9_bn1_moving_var: 128, \n",
      "stage2_unit9_conv1_weight: 128, 128, 3, 3, \n",
      "stage2_unit9_bn2_gamma: 128, \n",
      "stage2_unit9_bn2_beta: 128, \n",
      "stage2_unit9_bn2_moving_mean: 128, \n",
      "stage2_unit9_bn2_moving_var: 128, \n",
      "stage2_unit9_relu1_gamma: 128, \n",
      "reshape282: 4, \n",
      "stage2_unit9_conv2_weight: 128, 128, 3, 3, \n",
      "stage2_unit9_bn3_gamma: 128, \n",
      "stage2_unit9_bn3_beta: 128, \n",
      "stage2_unit9_bn3_moving_mean: 128, \n",
      "stage2_unit9_bn3_moving_var: 128, \n",
      "stage2_unit10_bn1_gamma: 128, \n",
      "stage2_unit10_bn1_beta: 128, \n",
      "stage2_unit10_bn1_moving_mean: 128, \n",
      "stage2_unit10_bn1_moving_var: 128, \n",
      "stage2_unit10_conv1_weight: 128, 128, 3, 3, \n",
      "stage2_unit10_bn2_gamma: 128, \n",
      "stage2_unit10_bn2_beta: 128, \n",
      "stage2_unit10_bn2_moving_mean: 128, \n",
      "stage2_unit10_bn2_moving_var: 128, \n",
      "stage2_unit10_relu1_gamma: 128, \n",
      "reshape304: 4, \n",
      "stage2_unit10_conv2_weight: 128, 128, 3, 3, \n",
      "stage2_unit10_bn3_gamma: 128, \n",
      "stage2_unit10_bn3_beta: 128, \n",
      "stage2_unit10_bn3_moving_mean: 128, \n",
      "stage2_unit10_bn3_moving_var: 128, \n",
      "stage2_unit11_bn1_gamma: 128, \n",
      "stage2_unit11_bn1_beta: 128, \n",
      "stage2_unit11_bn1_moving_mean: 128, \n",
      "stage2_unit11_bn1_moving_var: 128, \n",
      "stage2_unit11_conv1_weight: 128, 128, 3, 3, \n",
      "stage2_unit11_bn2_gamma: 128, \n",
      "stage2_unit11_bn2_beta: 128, \n",
      "stage2_unit11_bn2_moving_mean: 128, \n",
      "stage2_unit11_bn2_moving_var: 128, \n",
      "stage2_unit11_relu1_gamma: 128, \n",
      "reshape326: 4, \n",
      "stage2_unit11_conv2_weight: 128, 128, 3, 3, \n",
      "stage2_unit11_bn3_gamma: 128, \n",
      "stage2_unit11_bn3_beta: 128, \n",
      "stage2_unit11_bn3_moving_mean: 128, \n",
      "stage2_unit11_bn3_moving_var: 128, \n",
      "stage2_unit12_bn1_gamma: 128, \n",
      "stage2_unit12_bn1_beta: 128, \n",
      "stage2_unit12_bn1_moving_mean: 128, \n",
      "stage2_unit12_bn1_moving_var: 128, \n",
      "stage2_unit12_conv1_weight: 128, 128, 3, 3, \n",
      "stage2_unit12_bn2_gamma: 128, \n",
      "stage2_unit12_bn2_beta: 128, \n",
      "stage2_unit12_bn2_moving_mean: 128, \n",
      "stage2_unit12_bn2_moving_var: 128, \n",
      "stage2_unit12_relu1_gamma: 128, \n",
      "reshape348: 4, \n",
      "stage2_unit12_conv2_weight: 128, 128, 3, 3, \n",
      "stage2_unit12_bn3_gamma: 128, \n",
      "stage2_unit12_bn3_beta: 128, \n",
      "stage2_unit12_bn3_moving_mean: 128, \n",
      "stage2_unit12_bn3_moving_var: 128, \n",
      "stage2_unit13_bn1_gamma: 128, \n",
      "stage2_unit13_bn1_beta: 128, \n",
      "stage2_unit13_bn1_moving_mean: 128, \n",
      "stage2_unit13_bn1_moving_var: 128, \n",
      "stage2_unit13_conv1_weight: 128, 128, 3, 3, \n",
      "stage2_unit13_bn2_gamma: 128, \n",
      "stage2_unit13_bn2_beta: 128, \n",
      "stage2_unit13_bn2_moving_mean: 128, \n",
      "stage2_unit13_bn2_moving_var: 128, \n",
      "stage2_unit13_relu1_gamma: 128, \n",
      "reshape370: 4, \n",
      "stage2_unit13_conv2_weight: 128, 128, 3, 3, \n",
      "stage2_unit13_bn3_gamma: 128, \n",
      "stage2_unit13_bn3_beta: 128, \n",
      "stage2_unit13_bn3_moving_mean: 128, \n",
      "stage2_unit13_bn3_moving_var: 128, \n",
      "stage3_unit1_bn1_gamma: 128, \n",
      "stage3_unit1_bn1_beta: 128, \n",
      "stage3_unit1_bn1_moving_mean: 128, \n",
      "stage3_unit1_bn1_moving_var: 128, \n",
      "stage3_unit1_conv1_weight: 256, 128, 3, 3, \n",
      "stage3_unit1_bn2_gamma: 256, \n",
      "stage3_unit1_bn2_beta: 256, \n",
      "stage3_unit1_bn2_moving_mean: 256, \n",
      "stage3_unit1_bn2_moving_var: 256, \n",
      "stage3_unit1_relu1_gamma: 256, \n",
      "reshape392: 4, \n",
      "stage3_unit1_conv2_weight: 256, 256, 3, 3, \n",
      "stage3_unit1_bn3_gamma: 256, \n",
      "stage3_unit1_bn3_beta: 256, \n",
      "stage3_unit1_bn3_moving_mean: 256, \n",
      "stage3_unit1_bn3_moving_var: 256, \n",
      "stage3_unit1_conv1sc_weight: 256, 128, 1, 1, \n",
      "stage3_unit1_sc_gamma: 256, \n",
      "stage3_unit1_sc_beta: 256, \n",
      "stage3_unit1_sc_moving_mean: 256, \n",
      "stage3_unit1_sc_moving_var: 256, \n",
      "stage3_unit2_bn1_gamma: 256, \n",
      "stage3_unit2_bn1_beta: 256, \n",
      "stage3_unit2_bn1_moving_mean: 256, \n",
      "stage3_unit2_bn1_moving_var: 256, \n",
      "stage3_unit2_conv1_weight: 256, 256, 3, 3, \n",
      "stage3_unit2_bn2_gamma: 256, \n",
      "stage3_unit2_bn2_beta: 256, \n",
      "stage3_unit2_bn2_moving_mean: 256, \n",
      "stage3_unit2_bn2_moving_var: 256, \n",
      "stage3_unit2_relu1_gamma: 256, \n",
      "reshape421: 4, \n",
      "stage3_unit2_conv2_weight: 256, 256, 3, 3, \n",
      "stage3_unit2_bn3_gamma: 256, \n",
      "stage3_unit2_bn3_beta: 256, \n",
      "stage3_unit2_bn3_moving_mean: 256, \n",
      "stage3_unit2_bn3_moving_var: 256, \n",
      "stage3_unit3_bn1_gamma: 256, \n",
      "stage3_unit3_bn1_beta: 256, \n",
      "stage3_unit3_bn1_moving_mean: 256, \n",
      "stage3_unit3_bn1_moving_var: 256, \n",
      "stage3_unit3_conv1_weight: 256, 256, 3, 3, \n",
      "stage3_unit3_bn2_gamma: 256, \n",
      "stage3_unit3_bn2_beta: 256, \n",
      "stage3_unit3_bn2_moving_mean: 256, \n",
      "stage3_unit3_bn2_moving_var: 256, \n",
      "stage3_unit3_relu1_gamma: 256, \n",
      "reshape443: 4, \n",
      "stage3_unit3_conv2_weight: 256, 256, 3, 3, \n",
      "stage3_unit3_bn3_gamma: 256, \n",
      "stage3_unit3_bn3_beta: 256, \n",
      "stage3_unit3_bn3_moving_mean: 256, \n",
      "stage3_unit3_bn3_moving_var: 256, \n",
      "stage3_unit4_bn1_gamma: 256, \n",
      "stage3_unit4_bn1_beta: 256, \n",
      "stage3_unit4_bn1_moving_mean: 256, \n",
      "stage3_unit4_bn1_moving_var: 256, \n",
      "stage3_unit4_conv1_weight: 256, 256, 3, 3, \n",
      "stage3_unit4_bn2_gamma: 256, \n",
      "stage3_unit4_bn2_beta: 256, \n",
      "stage3_unit4_bn2_moving_mean: 256, \n",
      "stage3_unit4_bn2_moving_var: 256, \n",
      "stage3_unit4_relu1_gamma: 256, \n",
      "reshape465: 4, \n",
      "stage3_unit4_conv2_weight: 256, 256, 3, 3, \n",
      "stage3_unit4_bn3_gamma: 256, \n",
      "stage3_unit4_bn3_beta: 256, \n",
      "stage3_unit4_bn3_moving_mean: 256, \n",
      "stage3_unit4_bn3_moving_var: 256, \n",
      "stage3_unit5_bn1_gamma: 256, \n",
      "stage3_unit5_bn1_beta: 256, \n",
      "stage3_unit5_bn1_moving_mean: 256, \n",
      "stage3_unit5_bn1_moving_var: 256, \n",
      "stage3_unit5_conv1_weight: 256, 256, 3, 3, \n",
      "stage3_unit5_bn2_gamma: 256, \n",
      "stage3_unit5_bn2_beta: 256, \n",
      "stage3_unit5_bn2_moving_mean: 256, \n",
      "stage3_unit5_bn2_moving_var: 256, \n",
      "stage3_unit5_relu1_gamma: 256, \n",
      "reshape487: 4, \n",
      "stage3_unit5_conv2_weight: 256, 256, 3, 3, \n",
      "stage3_unit5_bn3_gamma: 256, \n",
      "stage3_unit5_bn3_beta: 256, \n",
      "stage3_unit5_bn3_moving_mean: 256, \n",
      "stage3_unit5_bn3_moving_var: 256, \n",
      "stage3_unit6_bn1_gamma: 256, \n",
      "stage3_unit6_bn1_beta: 256, \n",
      "stage3_unit6_bn1_moving_mean: 256, \n",
      "stage3_unit6_bn1_moving_var: 256, \n",
      "stage3_unit6_conv1_weight: 256, 256, 3, 3, \n",
      "stage3_unit6_bn2_gamma: 256, \n",
      "stage3_unit6_bn2_beta: 256, \n",
      "stage3_unit6_bn2_moving_mean: 256, \n",
      "stage3_unit6_bn2_moving_var: 256, \n",
      "stage3_unit6_relu1_gamma: 256, \n",
      "reshape509: 4, \n",
      "stage3_unit6_conv2_weight: 256, 256, 3, 3, \n",
      "stage3_unit6_bn3_gamma: 256, \n",
      "stage3_unit6_bn3_beta: 256, \n",
      "stage3_unit6_bn3_moving_mean: 256, \n",
      "stage3_unit6_bn3_moving_var: 256, \n",
      "stage3_unit7_bn1_gamma: 256, \n",
      "stage3_unit7_bn1_beta: 256, \n",
      "stage3_unit7_bn1_moving_mean: 256, \n",
      "stage3_unit7_bn1_moving_var: 256, \n",
      "stage3_unit7_conv1_weight: 256, 256, 3, 3, \n",
      "stage3_unit7_bn2_gamma: 256, \n",
      "stage3_unit7_bn2_beta: 256, \n",
      "stage3_unit7_bn2_moving_mean: 256, \n",
      "stage3_unit7_bn2_moving_var: 256, \n",
      "stage3_unit7_relu1_gamma: 256, \n",
      "reshape531: 4, \n",
      "stage3_unit7_conv2_weight: 256, 256, 3, 3, \n",
      "stage3_unit7_bn3_gamma: 256, \n",
      "stage3_unit7_bn3_beta: 256, \n",
      "stage3_unit7_bn3_moving_mean: 256, \n",
      "stage3_unit7_bn3_moving_var: 256, \n",
      "stage3_unit8_bn1_gamma: 256, \n",
      "stage3_unit8_bn1_beta: 256, \n",
      "stage3_unit8_bn1_moving_mean: 256, \n",
      "stage3_unit8_bn1_moving_var: 256, \n",
      "stage3_unit8_conv1_weight: 256, 256, 3, 3, \n",
      "stage3_unit8_bn2_gamma: 256, \n",
      "stage3_unit8_bn2_beta: 256, \n",
      "stage3_unit8_bn2_moving_mean: 256, \n",
      "stage3_unit8_bn2_moving_var: 256, \n",
      "stage3_unit8_relu1_gamma: 256, \n",
      "reshape553: 4, \n",
      "stage3_unit8_conv2_weight: 256, 256, 3, 3, \n",
      "stage3_unit8_bn3_gamma: 256, \n",
      "stage3_unit8_bn3_beta: 256, \n",
      "stage3_unit8_bn3_moving_mean: 256, \n",
      "stage3_unit8_bn3_moving_var: 256, \n",
      "stage3_unit9_bn1_gamma: 256, \n",
      "stage3_unit9_bn1_beta: 256, \n",
      "stage3_unit9_bn1_moving_mean: 256, \n",
      "stage3_unit9_bn1_moving_var: 256, \n",
      "stage3_unit9_conv1_weight: 256, 256, 3, 3, \n",
      "stage3_unit9_bn2_gamma: 256, \n",
      "stage3_unit9_bn2_beta: 256, \n",
      "stage3_unit9_bn2_moving_mean: 256, \n",
      "stage3_unit9_bn2_moving_var: 256, \n",
      "stage3_unit9_relu1_gamma: 256, \n",
      "reshape575: 4, \n",
      "stage3_unit9_conv2_weight: 256, 256, 3, 3, \n",
      "stage3_unit9_bn3_gamma: 256, \n",
      "stage3_unit9_bn3_beta: 256, \n",
      "stage3_unit9_bn3_moving_mean: 256, \n",
      "stage3_unit9_bn3_moving_var: 256, \n",
      "stage3_unit10_bn1_gamma: 256, \n",
      "stage3_unit10_bn1_beta: 256, \n",
      "stage3_unit10_bn1_moving_mean: 256, \n",
      "stage3_unit10_bn1_moving_var: 256, \n",
      "stage3_unit10_conv1_weight: 256, 256, 3, 3, \n",
      "stage3_unit10_bn2_gamma: 256, \n",
      "stage3_unit10_bn2_beta: 256, \n",
      "stage3_unit10_bn2_moving_mean: 256, \n",
      "stage3_unit10_bn2_moving_var: 256, \n",
      "stage3_unit10_relu1_gamma: 256, \n",
      "reshape597: 4, \n",
      "stage3_unit10_conv2_weight: 256, 256, 3, 3, \n",
      "stage3_unit10_bn3_gamma: 256, \n",
      "stage3_unit10_bn3_beta: 256, \n",
      "stage3_unit10_bn3_moving_mean: 256, \n",
      "stage3_unit10_bn3_moving_var: 256, \n",
      "stage3_unit11_bn1_gamma: 256, \n",
      "stage3_unit11_bn1_beta: 256, \n",
      "stage3_unit11_bn1_moving_mean: 256, \n",
      "stage3_unit11_bn1_moving_var: 256, \n",
      "stage3_unit11_conv1_weight: 256, 256, 3, 3, \n",
      "stage3_unit11_bn2_gamma: 256, \n",
      "stage3_unit11_bn2_beta: 256, \n",
      "stage3_unit11_bn2_moving_mean: 256, \n",
      "stage3_unit11_bn2_moving_var: 256, \n",
      "stage3_unit11_relu1_gamma: 256, \n",
      "reshape619: 4, \n",
      "stage3_unit11_conv2_weight: 256, 256, 3, 3, \n",
      "stage3_unit11_bn3_gamma: 256, \n",
      "stage3_unit11_bn3_beta: 256, \n",
      "stage3_unit11_bn3_moving_mean: 256, \n",
      "stage3_unit11_bn3_moving_var: 256, \n",
      "stage3_unit12_bn1_gamma: 256, \n",
      "stage3_unit12_bn1_beta: 256, \n",
      "stage3_unit12_bn1_moving_mean: 256, \n",
      "stage3_unit12_bn1_moving_var: 256, \n",
      "stage3_unit12_conv1_weight: 256, 256, 3, 3, \n",
      "stage3_unit12_bn2_gamma: 256, \n",
      "stage3_unit12_bn2_beta: 256, \n",
      "stage3_unit12_bn2_moving_mean: 256, \n",
      "stage3_unit12_bn2_moving_var: 256, \n",
      "stage3_unit12_relu1_gamma: 256, \n",
      "reshape641: 4, \n",
      "stage3_unit12_conv2_weight: 256, 256, 3, 3, \n",
      "stage3_unit12_bn3_gamma: 256, \n",
      "stage3_unit12_bn3_beta: 256, \n",
      "stage3_unit12_bn3_moving_mean: 256, \n",
      "stage3_unit12_bn3_moving_var: 256, \n",
      "stage3_unit13_bn1_gamma: 256, \n",
      "stage3_unit13_bn1_beta: 256, \n",
      "stage3_unit13_bn1_moving_mean: 256, \n",
      "stage3_unit13_bn1_moving_var: 256, \n",
      "stage3_unit13_conv1_weight: 256, 256, 3, 3, \n",
      "stage3_unit13_bn2_gamma: 256, \n",
      "stage3_unit13_bn2_beta: 256, \n",
      "stage3_unit13_bn2_moving_mean: 256, \n",
      "stage3_unit13_bn2_moving_var: 256, \n",
      "stage3_unit13_relu1_gamma: 256, \n",
      "reshape663: 4, \n",
      "stage3_unit13_conv2_weight: 256, 256, 3, 3, \n",
      "stage3_unit13_bn3_gamma: 256, \n",
      "stage3_unit13_bn3_beta: 256, \n",
      "stage3_unit13_bn3_moving_mean: 256, \n",
      "stage3_unit13_bn3_moving_var: 256, \n",
      "stage3_unit14_bn1_gamma: 256, \n",
      "stage3_unit14_bn1_beta: 256, \n",
      "stage3_unit14_bn1_moving_mean: 256, \n",
      "stage3_unit14_bn1_moving_var: 256, \n",
      "stage3_unit14_conv1_weight: 256, 256, 3, 3, \n",
      "stage3_unit14_bn2_gamma: 256, \n",
      "stage3_unit14_bn2_beta: 256, \n",
      "stage3_unit14_bn2_moving_mean: 256, \n",
      "stage3_unit14_bn2_moving_var: 256, \n",
      "stage3_unit14_relu1_gamma: 256, \n",
      "reshape685: 4, \n",
      "stage3_unit14_conv2_weight: 256, 256, 3, 3, \n",
      "stage3_unit14_bn3_gamma: 256, \n",
      "stage3_unit14_bn3_beta: 256, \n",
      "stage3_unit14_bn3_moving_mean: 256, \n",
      "stage3_unit14_bn3_moving_var: 256, \n",
      "stage3_unit15_bn1_gamma: 256, \n",
      "stage3_unit15_bn1_beta: 256, \n",
      "stage3_unit15_bn1_moving_mean: 256, \n",
      "stage3_unit15_bn1_moving_var: 256, \n",
      "stage3_unit15_conv1_weight: 256, 256, 3, 3, \n",
      "stage3_unit15_bn2_gamma: 256, \n",
      "stage3_unit15_bn2_beta: 256, \n",
      "stage3_unit15_bn2_moving_mean: 256, \n",
      "stage3_unit15_bn2_moving_var: 256, \n",
      "stage3_unit15_relu1_gamma: 256, \n",
      "reshape707: 4, \n",
      "stage3_unit15_conv2_weight: 256, 256, 3, 3, \n",
      "stage3_unit15_bn3_gamma: 256, \n",
      "stage3_unit15_bn3_beta: 256, \n",
      "stage3_unit15_bn3_moving_mean: 256, \n",
      "stage3_unit15_bn3_moving_var: 256, \n",
      "stage3_unit16_bn1_gamma: 256, \n",
      "stage3_unit16_bn1_beta: 256, \n",
      "stage3_unit16_bn1_moving_mean: 256, \n",
      "stage3_unit16_bn1_moving_var: 256, \n",
      "stage3_unit16_conv1_weight: 256, 256, 3, 3, \n",
      "stage3_unit16_bn2_gamma: 256, \n",
      "stage3_unit16_bn2_beta: 256, \n",
      "stage3_unit16_bn2_moving_mean: 256, \n",
      "stage3_unit16_bn2_moving_var: 256, \n",
      "stage3_unit16_relu1_gamma: 256, \n",
      "reshape729: 4, \n",
      "stage3_unit16_conv2_weight: 256, 256, 3, 3, \n",
      "stage3_unit16_bn3_gamma: 256, \n",
      "stage3_unit16_bn3_beta: 256, \n",
      "stage3_unit16_bn3_moving_mean: 256, \n",
      "stage3_unit16_bn3_moving_var: 256, \n",
      "stage3_unit17_bn1_gamma: 256, \n",
      "stage3_unit17_bn1_beta: 256, \n",
      "stage3_unit17_bn1_moving_mean: 256, \n",
      "stage3_unit17_bn1_moving_var: 256, \n",
      "stage3_unit17_conv1_weight: 256, 256, 3, 3, \n",
      "stage3_unit17_bn2_gamma: 256, \n",
      "stage3_unit17_bn2_beta: 256, \n",
      "stage3_unit17_bn2_moving_mean: 256, \n",
      "stage3_unit17_bn2_moving_var: 256, \n",
      "stage3_unit17_relu1_gamma: 256, \n",
      "reshape751: 4, \n",
      "stage3_unit17_conv2_weight: 256, 256, 3, 3, \n",
      "stage3_unit17_bn3_gamma: 256, \n",
      "stage3_unit17_bn3_beta: 256, \n",
      "stage3_unit17_bn3_moving_mean: 256, \n",
      "stage3_unit17_bn3_moving_var: 256, \n",
      "stage3_unit18_bn1_gamma: 256, \n",
      "stage3_unit18_bn1_beta: 256, \n",
      "stage3_unit18_bn1_moving_mean: 256, \n",
      "stage3_unit18_bn1_moving_var: 256, \n",
      "stage3_unit18_conv1_weight: 256, 256, 3, 3, \n",
      "stage3_unit18_bn2_gamma: 256, \n",
      "stage3_unit18_bn2_beta: 256, \n",
      "stage3_unit18_bn2_moving_mean: 256, \n",
      "stage3_unit18_bn2_moving_var: 256, \n",
      "stage3_unit18_relu1_gamma: 256, \n",
      "reshape773: 4, \n",
      "stage3_unit18_conv2_weight: 256, 256, 3, 3, \n",
      "stage3_unit18_bn3_gamma: 256, \n",
      "stage3_unit18_bn3_beta: 256, \n",
      "stage3_unit18_bn3_moving_mean: 256, \n",
      "stage3_unit18_bn3_moving_var: 256, \n",
      "stage3_unit19_bn1_gamma: 256, \n",
      "stage3_unit19_bn1_beta: 256, \n",
      "stage3_unit19_bn1_moving_mean: 256, \n",
      "stage3_unit19_bn1_moving_var: 256, \n",
      "stage3_unit19_conv1_weight: 256, 256, 3, 3, \n",
      "stage3_unit19_bn2_gamma: 256, \n",
      "stage3_unit19_bn2_beta: 256, \n",
      "stage3_unit19_bn2_moving_mean: 256, \n",
      "stage3_unit19_bn2_moving_var: 256, \n",
      "stage3_unit19_relu1_gamma: 256, \n",
      "reshape795: 4, \n",
      "stage3_unit19_conv2_weight: 256, 256, 3, 3, \n",
      "stage3_unit19_bn3_gamma: 256, \n",
      "stage3_unit19_bn3_beta: 256, \n",
      "stage3_unit19_bn3_moving_mean: 256, \n",
      "stage3_unit19_bn3_moving_var: 256, \n",
      "stage3_unit20_bn1_gamma: 256, \n",
      "stage3_unit20_bn1_beta: 256, \n",
      "stage3_unit20_bn1_moving_mean: 256, \n",
      "stage3_unit20_bn1_moving_var: 256, \n",
      "stage3_unit20_conv1_weight: 256, 256, 3, 3, \n",
      "stage3_unit20_bn2_gamma: 256, \n",
      "stage3_unit20_bn2_beta: 256, \n",
      "stage3_unit20_bn2_moving_mean: 256, \n",
      "stage3_unit20_bn2_moving_var: 256, \n",
      "stage3_unit20_relu1_gamma: 256, \n",
      "reshape817: 4, \n",
      "stage3_unit20_conv2_weight: 256, 256, 3, 3, \n",
      "stage3_unit20_bn3_gamma: 256, \n",
      "stage3_unit20_bn3_beta: 256, \n",
      "stage3_unit20_bn3_moving_mean: 256, \n",
      "stage3_unit20_bn3_moving_var: 256, \n",
      "stage3_unit21_bn1_gamma: 256, \n",
      "stage3_unit21_bn1_beta: 256, \n",
      "stage3_unit21_bn1_moving_mean: 256, \n",
      "stage3_unit21_bn1_moving_var: 256, \n",
      "stage3_unit21_conv1_weight: 256, 256, 3, 3, \n",
      "stage3_unit21_bn2_gamma: 256, \n",
      "stage3_unit21_bn2_beta: 256, \n",
      "stage3_unit21_bn2_moving_mean: 256, \n",
      "stage3_unit21_bn2_moving_var: 256, \n",
      "stage3_unit21_relu1_gamma: 256, \n",
      "reshape839: 4, \n",
      "stage3_unit21_conv2_weight: 256, 256, 3, 3, \n",
      "stage3_unit21_bn3_gamma: 256, \n",
      "stage3_unit21_bn3_beta: 256, \n",
      "stage3_unit21_bn3_moving_mean: 256, \n",
      "stage3_unit21_bn3_moving_var: 256, \n",
      "stage3_unit22_bn1_gamma: 256, \n",
      "stage3_unit22_bn1_beta: 256, \n",
      "stage3_unit22_bn1_moving_mean: 256, \n",
      "stage3_unit22_bn1_moving_var: 256, \n",
      "stage3_unit22_conv1_weight: 256, 256, 3, 3, \n",
      "stage3_unit22_bn2_gamma: 256, \n",
      "stage3_unit22_bn2_beta: 256, \n",
      "stage3_unit22_bn2_moving_mean: 256, \n",
      "stage3_unit22_bn2_moving_var: 256, \n",
      "stage3_unit22_relu1_gamma: 256, \n",
      "reshape861: 4, \n",
      "stage3_unit22_conv2_weight: 256, 256, 3, 3, \n",
      "stage3_unit22_bn3_gamma: 256, \n",
      "stage3_unit22_bn3_beta: 256, \n",
      "stage3_unit22_bn3_moving_mean: 256, \n",
      "stage3_unit22_bn3_moving_var: 256, \n",
      "stage3_unit23_bn1_gamma: 256, \n",
      "stage3_unit23_bn1_beta: 256, \n",
      "stage3_unit23_bn1_moving_mean: 256, \n",
      "stage3_unit23_bn1_moving_var: 256, \n",
      "stage3_unit23_conv1_weight: 256, 256, 3, 3, \n",
      "stage3_unit23_bn2_gamma: 256, \n",
      "stage3_unit23_bn2_beta: 256, \n",
      "stage3_unit23_bn2_moving_mean: 256, \n",
      "stage3_unit23_bn2_moving_var: 256, \n",
      "stage3_unit23_relu1_gamma: 256, \n",
      "reshape883: 4, \n",
      "stage3_unit23_conv2_weight: 256, 256, 3, 3, \n",
      "stage3_unit23_bn3_gamma: 256, \n",
      "stage3_unit23_bn3_beta: 256, \n",
      "stage3_unit23_bn3_moving_mean: 256, \n",
      "stage3_unit23_bn3_moving_var: 256, \n",
      "stage3_unit24_bn1_gamma: 256, \n",
      "stage3_unit24_bn1_beta: 256, \n",
      "stage3_unit24_bn1_moving_mean: 256, \n",
      "stage3_unit24_bn1_moving_var: 256, \n",
      "stage3_unit24_conv1_weight: 256, 256, 3, 3, \n",
      "stage3_unit24_bn2_gamma: 256, \n",
      "stage3_unit24_bn2_beta: 256, \n",
      "stage3_unit24_bn2_moving_mean: 256, \n",
      "stage3_unit24_bn2_moving_var: 256, \n",
      "stage3_unit24_relu1_gamma: 256, \n",
      "reshape905: 4, \n",
      "stage3_unit24_conv2_weight: 256, 256, 3, 3, \n",
      "stage3_unit24_bn3_gamma: 256, \n",
      "stage3_unit24_bn3_beta: 256, \n",
      "stage3_unit24_bn3_moving_mean: 256, \n",
      "stage3_unit24_bn3_moving_var: 256, \n",
      "stage3_unit25_bn1_gamma: 256, \n",
      "stage3_unit25_bn1_beta: 256, \n",
      "stage3_unit25_bn1_moving_mean: 256, \n",
      "stage3_unit25_bn1_moving_var: 256, \n",
      "stage3_unit25_conv1_weight: 256, 256, 3, 3, \n",
      "stage3_unit25_bn2_gamma: 256, \n",
      "stage3_unit25_bn2_beta: 256, \n",
      "stage3_unit25_bn2_moving_mean: 256, \n",
      "stage3_unit25_bn2_moving_var: 256, \n",
      "stage3_unit25_relu1_gamma: 256, \n",
      "reshape927: 4, \n",
      "stage3_unit25_conv2_weight: 256, 256, 3, 3, \n",
      "stage3_unit25_bn3_gamma: 256, \n",
      "stage3_unit25_bn3_beta: 256, \n",
      "stage3_unit25_bn3_moving_mean: 256, \n",
      "stage3_unit25_bn3_moving_var: 256, \n",
      "stage3_unit26_bn1_gamma: 256, \n",
      "stage3_unit26_bn1_beta: 256, \n",
      "stage3_unit26_bn1_moving_mean: 256, \n",
      "stage3_unit26_bn1_moving_var: 256, \n",
      "stage3_unit26_conv1_weight: 256, 256, 3, 3, \n",
      "stage3_unit26_bn2_gamma: 256, \n",
      "stage3_unit26_bn2_beta: 256, \n",
      "stage3_unit26_bn2_moving_mean: 256, \n",
      "stage3_unit26_bn2_moving_var: 256, \n",
      "stage3_unit26_relu1_gamma: 256, \n",
      "reshape949: 4, \n",
      "stage3_unit26_conv2_weight: 256, 256, 3, 3, \n",
      "stage3_unit26_bn3_gamma: 256, \n",
      "stage3_unit26_bn3_beta: 256, \n",
      "stage3_unit26_bn3_moving_mean: 256, \n",
      "stage3_unit26_bn3_moving_var: 256, \n",
      "stage3_unit27_bn1_gamma: 256, \n",
      "stage3_unit27_bn1_beta: 256, \n",
      "stage3_unit27_bn1_moving_mean: 256, \n",
      "stage3_unit27_bn1_moving_var: 256, \n",
      "stage3_unit27_conv1_weight: 256, 256, 3, 3, \n",
      "stage3_unit27_bn2_gamma: 256, \n",
      "stage3_unit27_bn2_beta: 256, \n",
      "stage3_unit27_bn2_moving_mean: 256, \n",
      "stage3_unit27_bn2_moving_var: 256, \n",
      "stage3_unit27_relu1_gamma: 256, \n",
      "reshape971: 4, \n",
      "stage3_unit27_conv2_weight: 256, 256, 3, 3, \n",
      "stage3_unit27_bn3_gamma: 256, \n",
      "stage3_unit27_bn3_beta: 256, \n",
      "stage3_unit27_bn3_moving_mean: 256, \n",
      "stage3_unit27_bn3_moving_var: 256, \n",
      "stage3_unit28_bn1_gamma: 256, \n",
      "stage3_unit28_bn1_beta: 256, \n",
      "stage3_unit28_bn1_moving_mean: 256, \n",
      "stage3_unit28_bn1_moving_var: 256, \n",
      "stage3_unit28_conv1_weight: 256, 256, 3, 3, \n",
      "stage3_unit28_bn2_gamma: 256, \n",
      "stage3_unit28_bn2_beta: 256, \n",
      "stage3_unit28_bn2_moving_mean: 256, \n",
      "stage3_unit28_bn2_moving_var: 256, \n",
      "stage3_unit28_relu1_gamma: 256, \n",
      "reshape993: 4, \n",
      "stage3_unit28_conv2_weight: 256, 256, 3, 3, \n",
      "stage3_unit28_bn3_gamma: 256, \n",
      "stage3_unit28_bn3_beta: 256, \n",
      "stage3_unit28_bn3_moving_mean: 256, \n",
      "stage3_unit28_bn3_moving_var: 256, \n",
      "stage3_unit29_bn1_gamma: 256, \n",
      "stage3_unit29_bn1_beta: 256, \n",
      "stage3_unit29_bn1_moving_mean: 256, \n",
      "stage3_unit29_bn1_moving_var: 256, \n",
      "stage3_unit29_conv1_weight: 256, 256, 3, 3, \n",
      "stage3_unit29_bn2_gamma: 256, \n",
      "stage3_unit29_bn2_beta: 256, \n",
      "stage3_unit29_bn2_moving_mean: 256, \n",
      "stage3_unit29_bn2_moving_var: 256, \n",
      "stage3_unit29_relu1_gamma: 256, \n",
      "reshape1015: 4, \n",
      "stage3_unit29_conv2_weight: 256, 256, 3, 3, \n",
      "stage3_unit29_bn3_gamma: 256, \n",
      "stage3_unit29_bn3_beta: 256, \n",
      "stage3_unit29_bn3_moving_mean: 256, \n",
      "stage3_unit29_bn3_moving_var: 256, \n",
      "stage3_unit30_bn1_gamma: 256, \n",
      "stage3_unit30_bn1_beta: 256, \n",
      "stage3_unit30_bn1_moving_mean: 256, \n",
      "stage3_unit30_bn1_moving_var: 256, \n",
      "stage3_unit30_conv1_weight: 256, 256, 3, 3, \n",
      "stage3_unit30_bn2_gamma: 256, \n",
      "stage3_unit30_bn2_beta: 256, \n",
      "stage3_unit30_bn2_moving_mean: 256, \n",
      "stage3_unit30_bn2_moving_var: 256, \n",
      "stage3_unit30_relu1_gamma: 256, \n",
      "reshape1037: 4, \n",
      "stage3_unit30_conv2_weight: 256, 256, 3, 3, \n",
      "stage3_unit30_bn3_gamma: 256, \n",
      "stage3_unit30_bn3_beta: 256, \n",
      "stage3_unit30_bn3_moving_mean: 256, \n",
      "stage3_unit30_bn3_moving_var: 256, \n",
      "stage4_unit1_bn1_gamma: 256, \n",
      "stage4_unit1_bn1_beta: 256, \n",
      "stage4_unit1_bn1_moving_mean: 256, \n",
      "stage4_unit1_bn1_moving_var: 256, \n",
      "stage4_unit1_conv1_weight: 512, 256, 3, 3, \n",
      "stage4_unit1_bn2_gamma: 512, \n",
      "stage4_unit1_bn2_beta: 512, \n",
      "stage4_unit1_bn2_moving_mean: 512, \n",
      "stage4_unit1_bn2_moving_var: 512, \n",
      "stage4_unit1_relu1_gamma: 512, \n",
      "reshape1059: 4, \n",
      "stage4_unit1_conv2_weight: 512, 512, 3, 3, \n",
      "stage4_unit1_bn3_gamma: 512, \n",
      "stage4_unit1_bn3_beta: 512, \n",
      "stage4_unit1_bn3_moving_mean: 512, \n",
      "stage4_unit1_bn3_moving_var: 512, \n",
      "stage4_unit1_conv1sc_weight: 512, 256, 1, 1, \n",
      "stage4_unit1_sc_gamma: 512, \n",
      "stage4_unit1_sc_beta: 512, \n",
      "stage4_unit1_sc_moving_mean: 512, \n",
      "stage4_unit1_sc_moving_var: 512, \n",
      "stage4_unit2_bn1_gamma: 512, \n",
      "stage4_unit2_bn1_beta: 512, \n",
      "stage4_unit2_bn1_moving_mean: 512, \n",
      "stage4_unit2_bn1_moving_var: 512, \n",
      "stage4_unit2_conv1_weight: 512, 512, 3, 3, \n",
      "stage4_unit2_bn2_gamma: 512, \n",
      "stage4_unit2_bn2_beta: 512, \n",
      "stage4_unit2_bn2_moving_mean: 512, \n",
      "stage4_unit2_bn2_moving_var: 512, \n",
      "stage4_unit2_relu1_gamma: 512, \n",
      "reshape1088: 4, \n",
      "stage4_unit2_conv2_weight: 512, 512, 3, 3, \n",
      "stage4_unit2_bn3_gamma: 512, \n",
      "stage4_unit2_bn3_beta: 512, \n",
      "stage4_unit2_bn3_moving_mean: 512, \n",
      "stage4_unit2_bn3_moving_var: 512, \n",
      "stage4_unit3_bn1_gamma: 512, \n",
      "stage4_unit3_bn1_beta: 512, \n",
      "stage4_unit3_bn1_moving_mean: 512, \n",
      "stage4_unit3_bn1_moving_var: 512, \n",
      "stage4_unit3_conv1_weight: 512, 512, 3, 3, \n",
      "stage4_unit3_bn2_gamma: 512, \n",
      "stage4_unit3_bn2_beta: 512, \n",
      "stage4_unit3_bn2_moving_mean: 512, \n",
      "stage4_unit3_bn2_moving_var: 512, \n",
      "stage4_unit3_relu1_gamma: 512, \n",
      "reshape1110: 4, \n",
      "stage4_unit3_conv2_weight: 512, 512, 3, 3, \n",
      "stage4_unit3_bn3_gamma: 512, \n",
      "stage4_unit3_bn3_beta: 512, \n",
      "stage4_unit3_bn3_moving_mean: 512, \n",
      "stage4_unit3_bn3_moving_var: 512, \n",
      "bn1_gamma: 512, \n",
      "bn1_beta: 512, \n",
      "bn1_moving_mean: 512, \n",
      "bn1_moving_var: 512, \n",
      "pre_fc1_weight: 512, 25088, \n",
      "pre_fc1_bias: 512, \n",
      "fc1_gamma: 512, \n",
      "fc1_beta: 512, \n",
      "fc1_moving_mean: 512, \n",
      "fc1_moving_var: 512, \n"
     ]
    }
   ],
   "source": [
    "## Find out input dimension\n",
    "import onnx\n",
    "model = onnx.load(\"/workspace/Courses/CV/inference/Bharat/FaceRecognition/pyt_retinaface_arcface/Pytorch_Retinaface/model_repository/onnx_arc/1/arcfaceresnet100-8.onnx\")\n",
    "# iterate through inputs of the graph\n",
    "for input in model.graph.input:\n",
    "    print (input.name, end=\": \")\n",
    "    # get type of input tensor\n",
    "    tensor_type = input.type.tensor_type\n",
    "    # check if it has a shape:\n",
    "    if (tensor_type.HasField(\"shape\")):\n",
    "        # iterate through dimensions of the shape:\n",
    "        for d in tensor_type.shape.dim:\n",
    "            # the dimension may have a definite (integer) value or a symbolic identifier or neither:\n",
    "            if (d.HasField(\"dim_value\")):\n",
    "                print (d.dim_value, end=\", \")  # known dimension\n",
    "            elif (d.HasField(\"dim_param\")):\n",
    "                print (d.dim_param, end=\", \")  # unknown dimension with symbolic name\n",
    "            else:\n",
    "                print (\"?\", end=\", \")  # unknown dimension with no name\n",
    "    else:\n",
    "        print (\"unknown rank\", end=\"\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mv model_repository/onnx_arc/1/arcfaceresnet100-8.onnx model_repository/onnx_arc/1/model.onnx "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "&&&& RUNNING TensorRT.trtexec # trtexec --onnx=model_repository/onnx_arc/1/model.onnx --explicitBatch --optShapes=data:8x3x112x112 --maxShapes=data:64x3x112x112 --minShapes=data:1x3x112x112 --saveEngine=model_repository/trt_fp16_arc/1/trt_fp16_arcface.plan --fp16\n",
      "[06/04/2021-09:57:22] [I] === Model Options ===\n",
      "[06/04/2021-09:57:22] [I] Format: ONNX\n",
      "[06/04/2021-09:57:22] [I] Model: model_repository/onnx_arc/1/model.onnx\n",
      "[06/04/2021-09:57:22] [I] Output:\n",
      "[06/04/2021-09:57:22] [I] === Build Options ===\n",
      "[06/04/2021-09:57:22] [I] Max batch: explicit\n",
      "[06/04/2021-09:57:22] [I] Workspace: 16 MiB\n",
      "[06/04/2021-09:57:22] [I] minTiming: 1\n",
      "[06/04/2021-09:57:22] [I] avgTiming: 8\n",
      "[06/04/2021-09:57:22] [I] Precision: FP32+FP16\n",
      "[06/04/2021-09:57:22] [I] Calibration: \n",
      "[06/04/2021-09:57:22] [I] Refit: Disabled\n",
      "[06/04/2021-09:57:22] [I] Safe mode: Disabled\n",
      "[06/04/2021-09:57:22] [I] Save engine: model_repository/trt_fp16_arc/1/trt_fp16_arcface.plan\n",
      "[06/04/2021-09:57:22] [I] Load engine: \n",
      "[06/04/2021-09:57:22] [I] Builder Cache: Enabled\n",
      "[06/04/2021-09:57:22] [I] NVTX verbosity: 0\n",
      "[06/04/2021-09:57:22] [I] Tactic sources: Using default tactic sources\n",
      "[06/04/2021-09:57:22] [I] Input(s)s format: fp32:CHW\n",
      "[06/04/2021-09:57:22] [I] Output(s)s format: fp32:CHW\n",
      "[06/04/2021-09:57:22] [I] Input build shape: data=1x3x112x112+8x3x112x112+64x3x112x112\n",
      "[06/04/2021-09:57:22] [I] Input calibration shapes: model\n",
      "[06/04/2021-09:57:22] [I] === System Options ===\n",
      "[06/04/2021-09:57:22] [I] Device: 0\n",
      "[06/04/2021-09:57:22] [I] DLACore: \n",
      "[06/04/2021-09:57:22] [I] Plugins:\n",
      "[06/04/2021-09:57:22] [I] === Inference Options ===\n",
      "[06/04/2021-09:57:22] [I] Batch: Explicit\n",
      "[06/04/2021-09:57:22] [I] Input inference shape: data=8x3x112x112\n",
      "[06/04/2021-09:57:22] [I] Iterations: 10\n",
      "[06/04/2021-09:57:22] [I] Duration: 3s (+ 200ms warm up)\n",
      "[06/04/2021-09:57:22] [I] Sleep time: 0ms\n",
      "[06/04/2021-09:57:22] [I] Streams: 1\n",
      "[06/04/2021-09:57:22] [I] ExposeDMA: Disabled\n",
      "[06/04/2021-09:57:22] [I] Data transfers: Enabled\n",
      "[06/04/2021-09:57:22] [I] Spin-wait: Disabled\n",
      "[06/04/2021-09:57:22] [I] Multithreading: Disabled\n",
      "[06/04/2021-09:57:22] [I] CUDA Graph: Disabled\n",
      "[06/04/2021-09:57:22] [I] Separate profiling: Disabled\n",
      "[06/04/2021-09:57:22] [I] Skip inference: Disabled\n",
      "[06/04/2021-09:57:22] [I] Inputs:\n",
      "[06/04/2021-09:57:22] [I] === Reporting Options ===\n",
      "[06/04/2021-09:57:22] [I] Verbose: Disabled\n",
      "[06/04/2021-09:57:22] [I] Averages: 10 inferences\n",
      "[06/04/2021-09:57:22] [I] Percentile: 99\n",
      "[06/04/2021-09:57:22] [I] Dump refittable layers:Disabled\n",
      "[06/04/2021-09:57:22] [I] Dump output: Disabled\n",
      "[06/04/2021-09:57:22] [I] Profile: Disabled\n",
      "[06/04/2021-09:57:22] [I] Export timing to JSON file: \n",
      "[06/04/2021-09:57:22] [I] Export output to JSON file: \n",
      "[06/04/2021-09:57:22] [I] Export profile to JSON file: \n",
      "[06/04/2021-09:57:22] [I] \n",
      "[06/04/2021-09:57:22] [I] === Device Information ===\n",
      "[06/04/2021-09:57:22] [I] Selected Device: Tesla V100-DGXS-32GB\n",
      "[06/04/2021-09:57:22] [I] Compute Capability: 7.0\n",
      "[06/04/2021-09:57:22] [I] SMs: 80\n",
      "[06/04/2021-09:57:22] [I] Compute Clock Rate: 1.53 GHz\n",
      "[06/04/2021-09:57:22] [I] Device Global Memory: 32478 MiB\n",
      "[06/04/2021-09:57:22] [I] Shared Memory per SM: 96 KiB\n",
      "[06/04/2021-09:57:22] [I] Memory Bus Width: 4096 bits (ECC enabled)\n",
      "[06/04/2021-09:57:22] [I] Memory Clock Rate: 0.877 GHz\n",
      "[06/04/2021-09:57:22] [I] \n",
      "----------------------------------------------------------------\n",
      "Input filename:   model_repository/onnx_arc/1/model.onnx\n",
      "ONNX IR version:  0.0.3\n",
      "Opset version:    8\n",
      "Producer name:    \n",
      "Producer version: \n",
      "Domain:           \n",
      "Model version:    0\n",
      "Doc string:       \n",
      "----------------------------------------------------------------\n",
      "[06/04/2021-09:57:38] [W] [TRT] /workspace/TensorRT/parsers/onnx/onnx2trt_utils.cpp:218: Your ONNX model has been generated with INT64 weights, while TensorRT does not natively support INT64. Attempting to cast down to INT32.\n",
      "[06/04/2021-09:58:10] [I] [TRT] Some tactics do not have sufficient workspace memory to run. Increasing workspace size may increase performance, please check verbose output.\n",
      "[06/04/2021-09:59:41] [I] [TRT] Detected 1 inputs and 1 output network tensors.\n",
      "[06/04/2021-09:59:42] [I] Engine built in 140.05 sec.\n",
      "[06/04/2021-09:59:43] [I] Starting inference\n",
      "[06/04/2021-09:59:46] [I] Warmup completed 0 queries over 200 ms\n",
      "[06/04/2021-09:59:46] [I] Timing trace has 0 queries over 3.0089 s\n",
      "[06/04/2021-09:59:46] [I] Trace averages of 10 runs:\n",
      "[06/04/2021-09:59:46] [I] Average on 10 runs - GPU latency: 3.1105 ms - Host latency: 3.13876 ms (end to end 6.14847 ms, enqueue 1.50728 ms)\n",
      "[06/04/2021-09:59:46] [I] Average on 10 runs - GPU latency: 3.10958 ms - Host latency: 3.13761 ms (end to end 6.15196 ms, enqueue 1.43767 ms)\n",
      "[06/04/2021-09:59:46] [I] Average on 10 runs - GPU latency: 3.11153 ms - Host latency: 3.14011 ms (end to end 6.15382 ms, enqueue 1.47346 ms)\n",
      "[06/04/2021-09:59:46] [I] Average on 10 runs - GPU latency: 3.11183 ms - Host latency: 3.14041 ms (end to end 6.15468 ms, enqueue 1.45157 ms)\n",
      "[06/04/2021-09:59:46] [I] Average on 10 runs - GPU latency: 3.11172 ms - Host latency: 3.14003 ms (end to end 6.1536 ms, enqueue 1.46953 ms)\n",
      "[06/04/2021-09:59:46] [I] Average on 10 runs - GPU latency: 3.11153 ms - Host latency: 3.13982 ms (end to end 6.1535 ms, enqueue 1.46534 ms)\n",
      "[06/04/2021-09:59:46] [I] Average on 10 runs - GPU latency: 3.11224 ms - Host latency: 3.14169 ms (end to end 6.15461 ms, enqueue 1.48034 ms)\n",
      "[06/04/2021-09:59:46] [I] Average on 10 runs - GPU latency: 3.11234 ms - Host latency: 3.14079 ms (end to end 6.15792 ms, enqueue 1.46606 ms)\n",
      "[06/04/2021-09:59:46] [I] Average on 10 runs - GPU latency: 3.11234 ms - Host latency: 3.14061 ms (end to end 6.15261 ms, enqueue 1.45302 ms)\n",
      "[06/04/2021-09:59:46] [I] Average on 10 runs - GPU latency: 3.11398 ms - Host latency: 3.14249 ms (end to end 6.15465 ms, enqueue 1.47039 ms)\n",
      "[06/04/2021-09:59:46] [I] Average on 10 runs - GPU latency: 3.11316 ms - Host latency: 3.14204 ms (end to end 6.16048 ms, enqueue 1.46703 ms)\n",
      "[06/04/2021-09:59:46] [I] Average on 10 runs - GPU latency: 3.11205 ms - Host latency: 3.14024 ms (end to end 6.15566 ms, enqueue 1.44965 ms)\n",
      "[06/04/2021-09:59:46] [I] Average on 10 runs - GPU latency: 3.11112 ms - Host latency: 3.1403 ms (end to end 5.86476 ms, enqueue 1.53552 ms)\n",
      "[06/04/2021-09:59:46] [I] Average on 10 runs - GPU latency: 3.11081 ms - Host latency: 3.13992 ms (end to end 6.15308 ms, enqueue 1.4475 ms)\n",
      "[06/04/2021-09:59:46] [I] Average on 10 runs - GPU latency: 3.10803 ms - Host latency: 3.13716 ms (end to end 6.14913 ms, enqueue 1.46743 ms)\n",
      "[06/04/2021-09:59:46] [I] Average on 10 runs - GPU latency: 3.1102 ms - Host latency: 3.13918 ms (end to end 6.14894 ms, enqueue 1.43378 ms)\n",
      "[06/04/2021-09:59:46] [I] Average on 10 runs - GPU latency: 3.1107 ms - Host latency: 3.1397 ms (end to end 6.1509 ms, enqueue 1.46741 ms)\n",
      "[06/04/2021-09:59:46] [I] Average on 10 runs - GPU latency: 3.11183 ms - Host latency: 3.14063 ms (end to end 6.15452 ms, enqueue 1.48184 ms)\n",
      "[06/04/2021-09:59:46] [I] Average on 10 runs - GPU latency: 3.11235 ms - Host latency: 3.142 ms (end to end 6.14796 ms, enqueue 1.47227 ms)\n",
      "[06/04/2021-09:59:46] [I] Average on 10 runs - GPU latency: 3.11113 ms - Host latency: 3.14015 ms (end to end 6.15066 ms, enqueue 1.45501 ms)\n",
      "[06/04/2021-09:59:46] [I] Average on 10 runs - GPU latency: 3.11317 ms - Host latency: 3.14186 ms (end to end 6.15812 ms, enqueue 1.42777 ms)\n",
      "[06/04/2021-09:59:46] [I] Average on 10 runs - GPU latency: 3.11122 ms - Host latency: 3.1404 ms (end to end 6.15466 ms, enqueue 1.43973 ms)\n",
      "[06/04/2021-09:59:46] [I] Average on 10 runs - GPU latency: 3.10833 ms - Host latency: 3.13629 ms (end to end 6.14781 ms, enqueue 1.46564 ms)\n",
      "[06/04/2021-09:59:46] [I] Average on 10 runs - GPU latency: 3.11133 ms - Host latency: 3.13987 ms (end to end 6.1525 ms, enqueue 1.45413 ms)\n",
      "[06/04/2021-09:59:46] [I] Average on 10 runs - GPU latency: 3.11276 ms - Host latency: 3.14207 ms (end to end 6.15754 ms, enqueue 1.47759 ms)\n",
      "[06/04/2021-09:59:46] [I] Average on 10 runs - GPU latency: 3.11459 ms - Host latency: 3.14517 ms (end to end 6.16102 ms, enqueue 1.46755 ms)\n",
      "[06/04/2021-09:59:46] [I] Average on 10 runs - GPU latency: 3.11438 ms - Host latency: 3.14351 ms (end to end 6.15906 ms, enqueue 1.46235 ms)\n",
      "[06/04/2021-09:59:46] [I] Average on 10 runs - GPU latency: 3.11202 ms - Host latency: 3.14169 ms (end to end 6.15489 ms, enqueue 1.46765 ms)\n",
      "[06/04/2021-09:59:46] [I] Average on 10 runs - GPU latency: 3.11196 ms - Host latency: 3.14152 ms (end to end 6.15668 ms, enqueue 1.45145 ms)\n",
      "[06/04/2021-09:59:46] [I] Average on 10 runs - GPU latency: 3.10948 ms - Host latency: 3.1386 ms (end to end 6.15039 ms, enqueue 1.44164 ms)\n",
      "[06/04/2021-09:59:46] [I] Average on 10 runs - GPU latency: 3.11051 ms - Host latency: 3.13965 ms (end to end 6.15083 ms, enqueue 1.45498 ms)\n",
      "[06/04/2021-09:59:46] [I] Average on 10 runs - GPU latency: 3.10885 ms - Host latency: 3.13763 ms (end to end 6.14722 ms, enqueue 1.43175 ms)\n",
      "[06/04/2021-09:59:46] [I] Average on 10 runs - GPU latency: 3.11133 ms - Host latency: 3.14052 ms (end to end 6.15414 ms, enqueue 1.42793 ms)\n",
      "[06/04/2021-09:59:46] [I] Average on 10 runs - GPU latency: 3.10743 ms - Host latency: 3.13611 ms (end to end 6.14749 ms, enqueue 1.43861 ms)\n",
      "[06/04/2021-09:59:46] [I] Average on 10 runs - GPU latency: 3.11165 ms - Host latency: 3.1407 ms (end to end 6.15614 ms, enqueue 1.46348 ms)\n",
      "[06/04/2021-09:59:46] [I] Average on 10 runs - GPU latency: 3.10773 ms - Host latency: 3.13701 ms (end to end 6.15054 ms, enqueue 1.42861 ms)\n",
      "[06/04/2021-09:59:46] [I] Average on 10 runs - GPU latency: 3.10858 ms - Host latency: 3.13721 ms (end to end 6.14939 ms, enqueue 1.43416 ms)\n",
      "[06/04/2021-09:59:46] [I] Average on 10 runs - GPU latency: 3.10936 ms - Host latency: 3.13843 ms (end to end 6.15198 ms, enqueue 1.43199 ms)\n",
      "[06/04/2021-09:59:46] [I] Average on 10 runs - GPU latency: 3.1106 ms - Host latency: 3.13959 ms (end to end 6.15408 ms, enqueue 1.44161 ms)\n",
      "[06/04/2021-09:59:46] [I] Average on 10 runs - GPU latency: 3.11058 ms - Host latency: 3.13885 ms (end to end 6.15446 ms, enqueue 1.46423 ms)\n",
      "[06/04/2021-09:59:46] [I] Average on 10 runs - GPU latency: 3.11256 ms - Host latency: 3.14177 ms (end to end 6.11636 ms, enqueue 1.46176 ms)\n",
      "[06/04/2021-09:59:46] [I] Average on 10 runs - GPU latency: 3.11283 ms - Host latency: 3.14176 ms (end to end 6.15519 ms, enqueue 1.46241 ms)\n",
      "[06/04/2021-09:59:46] [I] Average on 10 runs - GPU latency: 3.1108 ms - Host latency: 3.13961 ms (end to end 6.15647 ms, enqueue 1.46271 ms)\n",
      "[06/04/2021-09:59:46] [I] Average on 10 runs - GPU latency: 3.11287 ms - Host latency: 3.14259 ms (end to end 6.15682 ms, enqueue 1.47067 ms)\n",
      "[06/04/2021-09:59:46] [I] Average on 10 runs - GPU latency: 3.11226 ms - Host latency: 3.14113 ms (end to end 6.15453 ms, enqueue 1.52223 ms)\n",
      "[06/04/2021-09:59:46] [I] Average on 10 runs - GPU latency: 3.11276 ms - Host latency: 3.14207 ms (end to end 6.15662 ms, enqueue 1.45354 ms)\n",
      "[06/04/2021-09:59:46] [I] Average on 10 runs - GPU latency: 3.11097 ms - Host latency: 3.14076 ms (end to end 6.15352 ms, enqueue 1.47849 ms)\n",
      "[06/04/2021-09:59:46] [I] Average on 10 runs - GPU latency: 3.11287 ms - Host latency: 3.142 ms (end to end 6.15455 ms, enqueue 1.46151 ms)\n",
      "[06/04/2021-09:59:46] [I] Average on 10 runs - GPU latency: 3.11216 ms - Host latency: 3.14064 ms (end to end 6.15623 ms, enqueue 1.46394 ms)\n",
      "[06/04/2021-09:59:46] [I] Average on 10 runs - GPU latency: 3.11182 ms - Host latency: 3.14042 ms (end to end 6.15587 ms, enqueue 1.47917 ms)\n",
      "[06/04/2021-09:59:46] [I] Average on 10 runs - GPU latency: 3.11139 ms - Host latency: 3.14076 ms (end to end 6.15582 ms, enqueue 1.45905 ms)\n",
      "[06/04/2021-09:59:46] [I] Average on 10 runs - GPU latency: 3.11429 ms - Host latency: 3.14283 ms (end to end 6.15717 ms, enqueue 1.48309 ms)\n",
      "[06/04/2021-09:59:46] [I] Average on 10 runs - GPU latency: 3.1098 ms - Host latency: 3.13865 ms (end to end 6.14124 ms, enqueue 1.46473 ms)\n",
      "[06/04/2021-09:59:46] [I] Average on 10 runs - GPU latency: 3.11337 ms - Host latency: 3.14132 ms (end to end 5.54106 ms, enqueue 1.60817 ms)\n",
      "[06/04/2021-09:59:46] [I] Average on 10 runs - GPU latency: 3.10834 ms - Host latency: 3.13749 ms (end to end 6.1515 ms, enqueue 1.39806 ms)\n",
      "[06/04/2021-09:59:46] [I] Average on 10 runs - GPU latency: 3.10947 ms - Host latency: 3.13843 ms (end to end 6.15192 ms, enqueue 1.4521 ms)\n",
      "[06/04/2021-09:59:46] [I] Average on 10 runs - GPU latency: 3.10879 ms - Host latency: 3.13782 ms (end to end 6.14999 ms, enqueue 1.44897 ms)\n",
      "[06/04/2021-09:59:46] [I] Average on 10 runs - GPU latency: 3.11111 ms - Host latency: 3.14033 ms (end to end 6.15402 ms, enqueue 1.43185 ms)\n",
      "[06/04/2021-09:59:46] [I] Average on 10 runs - GPU latency: 3.11218 ms - Host latency: 3.1411 ms (end to end 6.15796 ms, enqueue 1.42388 ms)\n",
      "[06/04/2021-09:59:46] [I] Average on 10 runs - GPU latency: 3.11169 ms - Host latency: 3.14075 ms (end to end 6.15542 ms, enqueue 1.4645 ms)\n",
      "[06/04/2021-09:59:46] [I] Average on 10 runs - GPU latency: 3.11106 ms - Host latency: 3.14001 ms (end to end 6.15278 ms, enqueue 1.48748 ms)\n",
      "[06/04/2021-09:59:46] [I] Average on 10 runs - GPU latency: 3.11169 ms - Host latency: 3.14131 ms (end to end 6.15574 ms, enqueue 1.46096 ms)\n",
      "[06/04/2021-09:59:46] [I] Average on 10 runs - GPU latency: 3.11165 ms - Host latency: 3.14053 ms (end to end 6.15332 ms, enqueue 1.48481 ms)\n",
      "[06/04/2021-09:59:46] [I] Average on 10 runs - GPU latency: 3.1093 ms - Host latency: 3.13811 ms (end to end 6.14998 ms, enqueue 1.45181 ms)\n",
      "[06/04/2021-09:59:46] [I] Average on 10 runs - GPU latency: 3.11345 ms - Host latency: 3.14255 ms (end to end 6.15852 ms, enqueue 1.45632 ms)\n",
      "[06/04/2021-09:59:46] [I] Average on 10 runs - GPU latency: 3.1114 ms - Host latency: 3.14109 ms (end to end 6.15559 ms, enqueue 1.49114 ms)\n",
      "[06/04/2021-09:59:46] [I] Average on 10 runs - GPU latency: 3.11494 ms - Host latency: 3.14424 ms (end to end 6.15815 ms, enqueue 1.47124 ms)\n",
      "[06/04/2021-09:59:46] [I] Average on 10 runs - GPU latency: 3.18762 ms - Host latency: 3.22244 ms (end to end 5.13833 ms, enqueue 2.66514 ms)\n",
      "[06/04/2021-09:59:46] [I] Average on 10 runs - GPU latency: 3.10991 ms - Host latency: 3.14202 ms (end to end 6.13596 ms, enqueue 1.82612 ms)\n",
      "[06/04/2021-09:59:46] [I] Average on 10 runs - GPU latency: 3.11252 ms - Host latency: 3.14165 ms (end to end 6.15684 ms, enqueue 1.45276 ms)\n",
      "[06/04/2021-09:59:46] [I] Average on 10 runs - GPU latency: 3.11318 ms - Host latency: 3.14258 ms (end to end 6.15225 ms, enqueue 1.47275 ms)\n",
      "[06/04/2021-09:59:46] [I] Average on 10 runs - GPU latency: 3.11255 ms - Host latency: 3.14126 ms (end to end 6.15486 ms, enqueue 1.46497 ms)\n",
      "[06/04/2021-09:59:46] [I] Average on 10 runs - GPU latency: 3.11482 ms - Host latency: 3.14377 ms (end to end 6.151 ms, enqueue 1.50862 ms)\n",
      "[06/04/2021-09:59:46] [I] Average on 10 runs - GPU latency: 3.11511 ms - Host latency: 3.1448 ms (end to end 6.15974 ms, enqueue 1.47957 ms)\n",
      "[06/04/2021-09:59:46] [I] Average on 10 runs - GPU latency: 3.11326 ms - Host latency: 3.14197 ms (end to end 6.15525 ms, enqueue 1.48367 ms)\n",
      "[06/04/2021-09:59:46] [I] Average on 10 runs - GPU latency: 3.11553 ms - Host latency: 3.14697 ms (end to end 5.98289 ms, enqueue 2.25281 ms)\n",
      "[06/04/2021-09:59:46] [I] Average on 10 runs - GPU latency: 3.10974 ms - Host latency: 3.13967 ms (end to end 6.14629 ms, enqueue 1.57339 ms)\n",
      "[06/04/2021-09:59:46] [I] Average on 10 runs - GPU latency: 3.11282 ms - Host latency: 3.14216 ms (end to end 6.15867 ms, enqueue 1.48931 ms)\n",
      "[06/04/2021-09:59:46] [I] Average on 10 runs - GPU latency: 3.11338 ms - Host latency: 3.1427 ms (end to end 6.15432 ms, enqueue 1.48926 ms)\n",
      "[06/04/2021-09:59:46] [I] Average on 10 runs - GPU latency: 3.11348 ms - Host latency: 3.14285 ms (end to end 6.15198 ms, enqueue 1.48745 ms)\n",
      "[06/04/2021-09:59:46] [I] Average on 10 runs - GPU latency: 3.11282 ms - Host latency: 3.14214 ms (end to end 6.15615 ms, enqueue 1.50706 ms)\n",
      "[06/04/2021-09:59:46] [I] Average on 10 runs - GPU latency: 3.1094 ms - Host latency: 3.13875 ms (end to end 6.145 ms, enqueue 1.48728 ms)\n",
      "[06/04/2021-09:59:46] [I] Average on 10 runs - GPU latency: 3.11587 ms - Host latency: 3.14526 ms (end to end 6.15439 ms, enqueue 1.4845 ms)\n",
      "[06/04/2021-09:59:46] [I] Average on 10 runs - GPU latency: 3.11326 ms - Host latency: 3.14189 ms (end to end 6.15454 ms, enqueue 1.52537 ms)\n",
      "[06/04/2021-09:59:46] [I] Average on 10 runs - GPU latency: 3.11421 ms - Host latency: 3.14363 ms (end to end 6.15366 ms, enqueue 1.47083 ms)\n",
      "[06/04/2021-09:59:46] [I] Average on 10 runs - GPU latency: 3.11436 ms - Host latency: 3.14392 ms (end to end 6.15405 ms, enqueue 1.50784 ms)\n",
      "[06/04/2021-09:59:46] [I] Average on 10 runs - GPU latency: 3.11487 ms - Host latency: 3.14377 ms (end to end 6.15752 ms, enqueue 1.46895 ms)\n",
      "[06/04/2021-09:59:46] [I] Average on 10 runs - GPU latency: 3.11438 ms - Host latency: 3.14358 ms (end to end 6.15415 ms, enqueue 1.47646 ms)\n",
      "[06/04/2021-09:59:46] [I] Average on 10 runs - GPU latency: 3.11396 ms - Host latency: 3.14231 ms (end to end 6.15686 ms, enqueue 1.5051 ms)\n",
      "[06/04/2021-09:59:46] [I] Average on 10 runs - GPU latency: 3.11606 ms - Host latency: 3.14546 ms (end to end 6.16194 ms, enqueue 1.47 ms)\n",
      "[06/04/2021-09:59:46] [I] Average on 10 runs - GPU latency: 3.11331 ms - Host latency: 3.1428 ms (end to end 6.15422 ms, enqueue 1.51738 ms)\n",
      "[06/04/2021-09:59:46] [I] Average on 10 runs - GPU latency: 3.11504 ms - Host latency: 3.14382 ms (end to end 6.16118 ms, enqueue 1.47778 ms)\n",
      "[06/04/2021-09:59:46] [I] Average on 10 runs - GPU latency: 3.11492 ms - Host latency: 3.14341 ms (end to end 6.15869 ms, enqueue 1.46943 ms)\n",
      "[06/04/2021-09:59:46] [I] Average on 10 runs - GPU latency: 3.11348 ms - Host latency: 3.1426 ms (end to end 6.1585 ms, enqueue 1.47991 ms)\n",
      "[06/04/2021-09:59:46] [I] Average on 10 runs - GPU latency: 3.11431 ms - Host latency: 3.14343 ms (end to end 6.15769 ms, enqueue 1.47998 ms)\n",
      "[06/04/2021-09:59:46] [I] Host Latency\n",
      "[06/04/2021-09:59:46] [I] min: 3.12573 ms (end to end 3.15234 ms)\n",
      "[06/04/2021-09:59:46] [I] max: 3.72974 ms (end to end 6.17963 ms)\n",
      "[06/04/2021-09:59:46] [I] mean: 3.1419 ms (end to end 6.13163 ms)\n",
      "[06/04/2021-09:59:46] [I] median: 3.14087 ms (end to end 6.15472 ms)\n",
      "[06/04/2021-09:59:46] [I] percentile: 3.1552 ms at 99% (end to end 6.17316 ms at 99%)\n",
      "[06/04/2021-09:59:46] [I] throughput: 0 qps\n",
      "[06/04/2021-09:59:46] [I] walltime: 3.0089 s\n",
      "[06/04/2021-09:59:46] [I] Enqueue Time\n",
      "[06/04/2021-09:59:46] [I] min: 1.36926 ms\n",
      "[06/04/2021-09:59:46] [I] max: 4.36548 ms\n",
      "[06/04/2021-09:59:46] [I] median: 1.46686 ms\n",
      "[06/04/2021-09:59:46] [I] GPU Compute\n",
      "[06/04/2021-09:59:46] [I] min: 3.09656 ms\n",
      "[06/04/2021-09:59:46] [I] max: 3.69873 ms\n",
      "[06/04/2021-09:59:46] [I] mean: 3.11278 ms\n",
      "[06/04/2021-09:59:46] [I] median: 3.11194 ms\n",
      "[06/04/2021-09:59:46] [I] percentile: 3.12427 ms at 99%\n",
      "[06/04/2021-09:59:46] [I] total compute time: 2.97271 s\n",
      "&&&& PASSED TensorRT.trtexec # trtexec --onnx=model_repository/onnx_arc/1/model.onnx --explicitBatch --optShapes=data:8x3x112x112 --maxShapes=data:64x3x112x112 --minShapes=data:1x3x112x112 --saveEngine=model_repository/trt_fp16_arc/1/trt_fp16_arcface.plan --fp16\n"
     ]
    }
   ],
   "source": [
    "! trtexec --onnx=model_repository/onnx_arc/1/model.onnx --explicitBatch --optShapes=data:8x3x112x112 --maxShapes=data:64x3x112x112 --minShapes=data:1x3x112x112 --saveEngine=model_repository/trt_fp16_arc/1/trt_fp16_arcface.plan --fp16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "&&&& RUNNING TensorRT.trtexec # trtexec --onnx=model_repository/onnx_arc/1/model.onnx --explicitBatch --optShapes=data:8x3x112x112 --maxShapes=data:64x3x112x112 --minShapes=data:1x3x112x112 --saveEngine=model_repository/trt_fp32_arc/1/trt_fp32_arcface.plan\n",
      "[06/04/2021-09:59:47] [I] === Model Options ===\n",
      "[06/04/2021-09:59:47] [I] Format: ONNX\n",
      "[06/04/2021-09:59:47] [I] Model: model_repository/onnx_arc/1/model.onnx\n",
      "[06/04/2021-09:59:47] [I] Output:\n",
      "[06/04/2021-09:59:47] [I] === Build Options ===\n",
      "[06/04/2021-09:59:47] [I] Max batch: explicit\n",
      "[06/04/2021-09:59:47] [I] Workspace: 16 MiB\n",
      "[06/04/2021-09:59:47] [I] minTiming: 1\n",
      "[06/04/2021-09:59:47] [I] avgTiming: 8\n",
      "[06/04/2021-09:59:47] [I] Precision: FP32\n",
      "[06/04/2021-09:59:47] [I] Calibration: \n",
      "[06/04/2021-09:59:47] [I] Refit: Disabled\n",
      "[06/04/2021-09:59:47] [I] Safe mode: Disabled\n",
      "[06/04/2021-09:59:47] [I] Save engine: model_repository/trt_fp32_arc/1/trt_fp32_arcface.plan\n",
      "[06/04/2021-09:59:47] [I] Load engine: \n",
      "[06/04/2021-09:59:47] [I] Builder Cache: Enabled\n",
      "[06/04/2021-09:59:47] [I] NVTX verbosity: 0\n",
      "[06/04/2021-09:59:47] [I] Tactic sources: Using default tactic sources\n",
      "[06/04/2021-09:59:47] [I] Input(s)s format: fp32:CHW\n",
      "[06/04/2021-09:59:47] [I] Output(s)s format: fp32:CHW\n",
      "[06/04/2021-09:59:47] [I] Input build shape: data=1x3x112x112+8x3x112x112+64x3x112x112\n",
      "[06/04/2021-09:59:47] [I] Input calibration shapes: model\n",
      "[06/04/2021-09:59:47] [I] === System Options ===\n",
      "[06/04/2021-09:59:47] [I] Device: 0\n",
      "[06/04/2021-09:59:47] [I] DLACore: \n",
      "[06/04/2021-09:59:47] [I] Plugins:\n",
      "[06/04/2021-09:59:47] [I] === Inference Options ===\n",
      "[06/04/2021-09:59:47] [I] Batch: Explicit\n",
      "[06/04/2021-09:59:47] [I] Input inference shape: data=8x3x112x112\n",
      "[06/04/2021-09:59:47] [I] Iterations: 10\n",
      "[06/04/2021-09:59:47] [I] Duration: 3s (+ 200ms warm up)\n",
      "[06/04/2021-09:59:47] [I] Sleep time: 0ms\n",
      "[06/04/2021-09:59:47] [I] Streams: 1\n",
      "[06/04/2021-09:59:47] [I] ExposeDMA: Disabled\n",
      "[06/04/2021-09:59:47] [I] Data transfers: Enabled\n",
      "[06/04/2021-09:59:47] [I] Spin-wait: Disabled\n",
      "[06/04/2021-09:59:47] [I] Multithreading: Disabled\n",
      "[06/04/2021-09:59:47] [I] CUDA Graph: Disabled\n",
      "[06/04/2021-09:59:47] [I] Separate profiling: Disabled\n",
      "[06/04/2021-09:59:47] [I] Skip inference: Disabled\n",
      "[06/04/2021-09:59:47] [I] Inputs:\n",
      "[06/04/2021-09:59:47] [I] === Reporting Options ===\n",
      "[06/04/2021-09:59:47] [I] Verbose: Disabled\n",
      "[06/04/2021-09:59:47] [I] Averages: 10 inferences\n",
      "[06/04/2021-09:59:47] [I] Percentile: 99\n",
      "[06/04/2021-09:59:47] [I] Dump refittable layers:Disabled\n",
      "[06/04/2021-09:59:47] [I] Dump output: Disabled\n",
      "[06/04/2021-09:59:47] [I] Profile: Disabled\n",
      "[06/04/2021-09:59:47] [I] Export timing to JSON file: \n",
      "[06/04/2021-09:59:47] [I] Export output to JSON file: \n",
      "[06/04/2021-09:59:47] [I] Export profile to JSON file: \n",
      "[06/04/2021-09:59:47] [I] \n",
      "[06/04/2021-09:59:47] [I] === Device Information ===\n",
      "[06/04/2021-09:59:47] [I] Selected Device: Tesla V100-DGXS-32GB\n",
      "[06/04/2021-09:59:47] [I] Compute Capability: 7.0\n",
      "[06/04/2021-09:59:47] [I] SMs: 80\n",
      "[06/04/2021-09:59:47] [I] Compute Clock Rate: 1.53 GHz\n",
      "[06/04/2021-09:59:47] [I] Device Global Memory: 32478 MiB\n",
      "[06/04/2021-09:59:47] [I] Shared Memory per SM: 96 KiB\n",
      "[06/04/2021-09:59:47] [I] Memory Bus Width: 4096 bits (ECC enabled)\n",
      "[06/04/2021-09:59:47] [I] Memory Clock Rate: 0.877 GHz\n",
      "[06/04/2021-09:59:47] [I] \n",
      "----------------------------------------------------------------\n",
      "Input filename:   model_repository/onnx_arc/1/model.onnx\n",
      "ONNX IR version:  0.0.3\n",
      "Opset version:    8\n",
      "Producer name:    \n",
      "Producer version: \n",
      "Domain:           \n",
      "Model version:    0\n",
      "Doc string:       \n",
      "----------------------------------------------------------------\n",
      "[06/04/2021-10:00:03] [W] [TRT] /workspace/TensorRT/parsers/onnx/onnx2trt_utils.cpp:218: Your ONNX model has been generated with INT64 weights, while TensorRT does not natively support INT64. Attempting to cast down to INT32.\n",
      "[06/04/2021-10:00:18] [I] [TRT] Some tactics do not have sufficient workspace memory to run. Increasing workspace size may increase performance, please check verbose output.\n",
      "[06/04/2021-10:00:40] [I] [TRT] Detected 1 inputs and 1 output network tensors.\n",
      "[06/04/2021-10:00:43] [I] Engine built in 55.6896 sec.\n",
      "[06/04/2021-10:00:43] [I] Starting inference\n",
      "[06/04/2021-10:00:46] [I] Warmup completed 0 queries over 200 ms\n",
      "[06/04/2021-10:00:46] [I] Timing trace has 0 queries over 3.00654 s\n",
      "[06/04/2021-10:00:46] [I] Trace averages of 10 runs:\n",
      "[06/04/2021-10:00:46] [I] Average on 10 runs - GPU latency: 5.83096 ms - Host latency: 5.86059 ms (end to end 10.8469 ms, enqueue 1.58393 ms)\n",
      "[06/04/2021-10:00:46] [I] Average on 10 runs - GPU latency: 5.81632 ms - Host latency: 5.84513 ms (end to end 11.5418 ms, enqueue 1.56386 ms)\n",
      "[06/04/2021-10:00:46] [I] Average on 10 runs - GPU latency: 5.76266 ms - Host latency: 5.79197 ms (end to end 11.1698 ms, enqueue 1.59029 ms)\n",
      "[06/04/2021-10:00:46] [I] Average on 10 runs - GPU latency: 5.51219 ms - Host latency: 5.54115 ms (end to end 10.912 ms, enqueue 1.48271 ms)\n",
      "[06/04/2021-10:00:46] [I] Average on 10 runs - GPU latency: 5.49335 ms - Host latency: 5.52225 ms (end to end 10.8954 ms, enqueue 1.55488 ms)\n",
      "[06/04/2021-10:00:46] [I] Average on 10 runs - GPU latency: 5.48875 ms - Host latency: 5.51844 ms (end to end 10.8847 ms, enqueue 1.57286 ms)\n",
      "[06/04/2021-10:00:46] [I] Average on 10 runs - GPU latency: 5.48793 ms - Host latency: 5.51635 ms (end to end 10.8872 ms, enqueue 1.49714 ms)\n",
      "[06/04/2021-10:00:46] [I] Average on 10 runs - GPU latency: 5.48403 ms - Host latency: 5.51395 ms (end to end 10.8776 ms, enqueue 1.53923 ms)\n",
      "[06/04/2021-10:00:46] [I] Average on 10 runs - GPU latency: 5.48608 ms - Host latency: 5.5163 ms (end to end 10.8744 ms, enqueue 1.59956 ms)\n",
      "[06/04/2021-10:00:46] [I] Average on 10 runs - GPU latency: 5.48731 ms - Host latency: 5.51924 ms (end to end 10.872 ms, enqueue 1.67721 ms)\n",
      "[06/04/2021-10:00:46] [I] Average on 10 runs - GPU latency: 5.4866 ms - Host latency: 5.51843 ms (end to end 10.8727 ms, enqueue 1.62466 ms)\n",
      "[06/04/2021-10:00:46] [I] Average on 10 runs - GPU latency: 5.48834 ms - Host latency: 5.51982 ms (end to end 10.8791 ms, enqueue 1.62778 ms)\n",
      "[06/04/2021-10:00:46] [I] Average on 10 runs - GPU latency: 5.48865 ms - Host latency: 5.51954 ms (end to end 10.881 ms, enqueue 1.64877 ms)\n",
      "[06/04/2021-10:00:46] [I] Average on 10 runs - GPU latency: 5.48936 ms - Host latency: 5.52133 ms (end to end 10.8766 ms, enqueue 1.66817 ms)\n",
      "[06/04/2021-10:00:46] [I] Average on 10 runs - GPU latency: 5.4875 ms - Host latency: 5.51964 ms (end to end 10.8771 ms, enqueue 1.6473 ms)\n",
      "[06/04/2021-10:00:46] [I] Average on 10 runs - GPU latency: 5.48956 ms - Host latency: 5.521 ms (end to end 10.8818 ms, enqueue 1.64265 ms)\n",
      "[06/04/2021-10:00:46] [I] Average on 10 runs - GPU latency: 5.48804 ms - Host latency: 5.51927 ms (end to end 10.8763 ms, enqueue 1.66136 ms)\n",
      "[06/04/2021-10:00:46] [I] Average on 10 runs - GPU latency: 5.48619 ms - Host latency: 5.51759 ms (end to end 10.8771 ms, enqueue 1.66342 ms)\n",
      "[06/04/2021-10:00:46] [I] Average on 10 runs - GPU latency: 5.48666 ms - Host latency: 5.51904 ms (end to end 10.8748 ms, enqueue 1.66382 ms)\n",
      "[06/04/2021-10:00:46] [I] Average on 10 runs - GPU latency: 5.48855 ms - Host latency: 5.51974 ms (end to end 10.8783 ms, enqueue 1.63671 ms)\n",
      "[06/04/2021-10:00:46] [I] Average on 10 runs - GPU latency: 5.4866 ms - Host latency: 5.51821 ms (end to end 10.8769 ms, enqueue 1.65295 ms)\n",
      "[06/04/2021-10:00:46] [I] Average on 10 runs - GPU latency: 5.48505 ms - Host latency: 5.51691 ms (end to end 10.8737 ms, enqueue 1.62957 ms)\n",
      "[06/04/2021-10:00:46] [I] Average on 10 runs - GPU latency: 5.48516 ms - Host latency: 5.51606 ms (end to end 10.8724 ms, enqueue 1.62426 ms)\n",
      "[06/04/2021-10:00:46] [I] Average on 10 runs - GPU latency: 5.4907 ms - Host latency: 5.52211 ms (end to end 10.8831 ms, enqueue 1.64229 ms)\n",
      "[06/04/2021-10:00:46] [I] Average on 10 runs - GPU latency: 5.491 ms - Host latency: 5.52328 ms (end to end 10.8844 ms, enqueue 1.65735 ms)\n",
      "[06/04/2021-10:00:46] [I] Average on 10 runs - GPU latency: 5.48813 ms - Host latency: 5.51874 ms (end to end 10.8785 ms, enqueue 1.64447 ms)\n",
      "[06/04/2021-10:00:46] [I] Average on 10 runs - GPU latency: 5.49132 ms - Host latency: 5.52339 ms (end to end 10.157 ms, enqueue 1.64062 ms)\n",
      "[06/04/2021-10:00:46] [I] Average on 10 runs - GPU latency: 5.48629 ms - Host latency: 5.51565 ms (end to end 10.8789 ms, enqueue 1.49924 ms)\n",
      "[06/04/2021-10:00:46] [I] Average on 10 runs - GPU latency: 5.48514 ms - Host latency: 5.51597 ms (end to end 10.8751 ms, enqueue 1.64003 ms)\n",
      "[06/04/2021-10:00:46] [I] Average on 10 runs - GPU latency: 5.48619 ms - Host latency: 5.51765 ms (end to end 10.8766 ms, enqueue 1.66324 ms)\n",
      "[06/04/2021-10:00:46] [I] Average on 10 runs - GPU latency: 5.49006 ms - Host latency: 5.52219 ms (end to end 10.8805 ms, enqueue 1.66599 ms)\n",
      "[06/04/2021-10:00:46] [I] Average on 10 runs - GPU latency: 5.48903 ms - Host latency: 5.52025 ms (end to end 10.8771 ms, enqueue 1.64835 ms)\n",
      "[06/04/2021-10:00:46] [I] Average on 10 runs - GPU latency: 5.48693 ms - Host latency: 5.51859 ms (end to end 10.8785 ms, enqueue 1.66018 ms)\n",
      "[06/04/2021-10:00:46] [I] Average on 10 runs - GPU latency: 5.48635 ms - Host latency: 5.51829 ms (end to end 10.8742 ms, enqueue 1.69114 ms)\n",
      "[06/04/2021-10:00:46] [I] Average on 10 runs - GPU latency: 5.48616 ms - Host latency: 5.51714 ms (end to end 10.8793 ms, enqueue 1.61782 ms)\n",
      "[06/04/2021-10:00:46] [I] Average on 10 runs - GPU latency: 5.4876 ms - Host latency: 5.51948 ms (end to end 10.88 ms, enqueue 1.63621 ms)\n",
      "[06/04/2021-10:00:46] [I] Average on 10 runs - GPU latency: 5.48689 ms - Host latency: 5.51841 ms (end to end 10.8781 ms, enqueue 1.66475 ms)\n",
      "[06/04/2021-10:00:46] [I] Average on 10 runs - GPU latency: 5.48677 ms - Host latency: 5.51824 ms (end to end 10.8763 ms, enqueue 1.67087 ms)\n",
      "[06/04/2021-10:00:46] [I] Average on 10 runs - GPU latency: 5.48379 ms - Host latency: 5.51516 ms (end to end 10.8739 ms, enqueue 1.6491 ms)\n",
      "[06/04/2021-10:00:46] [I] Average on 10 runs - GPU latency: 5.48782 ms - Host latency: 5.52019 ms (end to end 10.873 ms, enqueue 1.62017 ms)\n",
      "[06/04/2021-10:00:46] [I] Average on 10 runs - GPU latency: 5.48843 ms - Host latency: 5.5248 ms (end to end 10.8305 ms, enqueue 1.9905 ms)\n",
      "[06/04/2021-10:00:46] [I] Average on 10 runs - GPU latency: 5.48738 ms - Host latency: 5.51726 ms (end to end 10.8991 ms, enqueue 1.45464 ms)\n",
      "[06/04/2021-10:00:46] [I] Average on 10 runs - GPU latency: 5.48982 ms - Host latency: 5.52034 ms (end to end 10.8934 ms, enqueue 1.62842 ms)\n",
      "[06/04/2021-10:00:46] [I] Average on 10 runs - GPU latency: 5.48689 ms - Host latency: 5.51794 ms (end to end 10.8842 ms, enqueue 1.6447 ms)\n",
      "[06/04/2021-10:00:46] [I] Average on 10 runs - GPU latency: 5.48762 ms - Host latency: 5.51794 ms (end to end 10.8887 ms, enqueue 1.6366 ms)\n",
      "[06/04/2021-10:00:46] [I] Average on 10 runs - GPU latency: 5.48723 ms - Host latency: 5.51729 ms (end to end 10.887 ms, enqueue 1.60986 ms)\n",
      "[06/04/2021-10:00:46] [I] Average on 10 runs - GPU latency: 5.48599 ms - Host latency: 5.51672 ms (end to end 10.8834 ms, enqueue 1.61721 ms)\n",
      "[06/04/2021-10:00:46] [I] Average on 10 runs - GPU latency: 5.48489 ms - Host latency: 5.51584 ms (end to end 10.8825 ms, enqueue 1.63877 ms)\n",
      "[06/04/2021-10:00:46] [I] Average on 10 runs - GPU latency: 5.48455 ms - Host latency: 5.51479 ms (end to end 10.8805 ms, enqueue 1.64575 ms)\n",
      "[06/04/2021-10:00:46] [I] Average on 10 runs - GPU latency: 5.48572 ms - Host latency: 5.51646 ms (end to end 10.883 ms, enqueue 1.63118 ms)\n",
      "[06/04/2021-10:00:46] [I] Average on 10 runs - GPU latency: 5.48657 ms - Host latency: 5.51763 ms (end to end 10.8837 ms, enqueue 1.64639 ms)\n",
      "[06/04/2021-10:00:46] [I] Average on 10 runs - GPU latency: 5.48687 ms - Host latency: 5.51775 ms (end to end 10.8864 ms, enqueue 1.64585 ms)\n",
      "[06/04/2021-10:00:46] [I] Average on 10 runs - GPU latency: 5.48923 ms - Host latency: 5.52019 ms (end to end 10.8906 ms, enqueue 1.64216 ms)\n",
      "[06/04/2021-10:00:46] [I] Average on 10 runs - GPU latency: 5.48416 ms - Host latency: 5.51423 ms (end to end 10.8838 ms, enqueue 1.62219 ms)\n",
      "[06/04/2021-10:00:46] [I] Host Latency\n",
      "[06/04/2021-10:00:46] [I] min: 5.50629 ms (end to end 5.57507 ms)\n",
      "[06/04/2021-10:00:46] [I] max: 5.88206 ms (end to end 11.5983 ms)\n",
      "[06/04/2021-10:00:46] [I] mean: 5.53637 ms (end to end 10.8837 ms)\n",
      "[06/04/2021-10:00:46] [I] median: 5.51868 ms (end to end 10.8809 ms)\n",
      "[06/04/2021-10:00:46] [I] percentile: 5.86134 ms at 99% (end to end 11.5519 ms at 99%)\n",
      "[06/04/2021-10:00:46] [I] throughput: 0 qps\n",
      "[06/04/2021-10:00:46] [I] walltime: 3.00654 s\n",
      "[06/04/2021-10:00:46] [I] Enqueue Time\n",
      "[06/04/2021-10:00:46] [I] min: 1.1123 ms\n",
      "[06/04/2021-10:00:46] [I] max: 2.92505 ms\n",
      "[06/04/2021-10:00:46] [I] median: 1.64929 ms\n",
      "[06/04/2021-10:00:46] [I] GPU Compute\n",
      "[06/04/2021-10:00:46] [I] min: 5.47729 ms\n",
      "[06/04/2021-10:00:46] [I] max: 5.85318 ms\n",
      "[06/04/2021-10:00:46] [I] mean: 5.50536 ms\n",
      "[06/04/2021-10:00:46] [I] median: 5.48764 ms\n",
      "[06/04/2021-10:00:46] [I] percentile: 5.83168 ms at 99%\n",
      "[06/04/2021-10:00:46] [I] total compute time: 2.9784 s\n",
      "&&&& PASSED TensorRT.trtexec # trtexec --onnx=model_repository/onnx_arc/1/model.onnx --explicitBatch --optShapes=data:8x3x112x112 --maxShapes=data:64x3x112x112 --minShapes=data:1x3x112x112 --saveEngine=model_repository/trt_fp32_arc/1/trt_fp32_arcface.plan\n"
     ]
    }
   ],
   "source": [
    "! trtexec --onnx=model_repository/onnx_arc/1/model.onnx --explicitBatch --optShapes=data:8x3x112x112 --maxShapes=data:64x3x112x112 --minShapes=data:1x3x112x112 --saveEngine=model_repository/trt_fp32_arc/1/trt_fp32_arcface.plan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Triton Server"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> docker run --gpus all --net=host -v /path/to/model_repository/:/models --ipc=host  nvcr.io/nvidia/tritonserver:20.12-py3 tritonserver --model-repository=/models --strict-model-config=false"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Triton Client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> docker run -it -v /home/path/:/workspace/data --net=host nvcr.io/nvidia/tritonserver:20.12-py3-sdk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf `find -type d -name .ipynb_checkpoints`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -v localhost:8000/v2/models/onnx_retina/config "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -v localhost:8000/v2/models/trt_fp16_retina/config "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -v localhost:8000/v2/models/onnx_arc/config "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -v localhost:8000/v2/models/trt_fp16_arc/config "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Measurement Settings ***\n",
      "  Batch size: 1\n",
      "  Measurement window: 5000 msec\n",
      "  Using synchronous calls for inference\n",
      "  Stabilizing using average latency\n",
      "\n",
      "Request concurrency: 1\n",
      "  Client: \n",
      "    Request count: 276\n",
      "    Throughput: 55.2 infer/sec\n",
      "    Avg latency: 18092 usec (standard deviation 2709 usec)\n",
      "    p50 latency: 17525 usec\n",
      "    p90 latency: 20481 usec\n",
      "    p95 latency: 20875 usec\n",
      "    p99 latency: 21293 usec\n",
      "    Avg gRPC time: 18017 usec ((un)marshal request/response 978 usec + response wait 17039 usec)\n",
      "  Server: \n",
      "    Inference count: 331\n",
      "    Execution count: 331\n",
      "    Successful request count: 331\n",
      "    Avg request latency: 10541 usec (overhead 3 usec + queue 23 usec + compute input 3084 usec + compute infer 7138 usec + compute output 293 usec)\n",
      "\n",
      "Inferences/Second vs. Client Average Batch Latency\n",
      "Concurrency: 1, throughput: 55.2 infer/sec, latency 18092 usec\n"
     ]
    }
   ],
   "source": [
    "!perf_analyzer -m trt_fp32_retina -b 1 -u localhost:8001 -i grpc --concurrency-range 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Measurement Settings ***\n",
      "  Batch size: 1\n",
      "  Measurement window: 5000 msec\n",
      "  Using synchronous calls for inference\n",
      "  Stabilizing using average latency\n",
      "\n",
      "Request concurrency: 1\n",
      "  Client: \n",
      "    Request count: 359\n",
      "    Throughput: 71.8 infer/sec\n",
      "    Avg latency: 13922 usec (standard deviation 2424 usec)\n",
      "    p50 latency: 13220 usec\n",
      "    p90 latency: 15907 usec\n",
      "    p95 latency: 16439 usec\n",
      "    p99 latency: 20175 usec\n",
      "    Avg gRPC time: 13726 usec ((un)marshal request/response 920 usec + response wait 12806 usec)\n",
      "  Server: \n",
      "    Inference count: 432\n",
      "    Execution count: 432\n",
      "    Successful request count: 432\n",
      "    Avg request latency: 6376 usec (overhead 2 usec + queue 23 usec + compute input 2652 usec + compute infer 3395 usec + compute output 304 usec)\n",
      "\n",
      "Inferences/Second vs. Client Average Batch Latency\n",
      "Concurrency: 1, throughput: 71.8 infer/sec, latency 13922 usec\n"
     ]
    }
   ],
   "source": [
    "!perf_analyzer -m trt_fp16_retina -b 1 -u localhost:8001 -i grpc --concurrency-range 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Measurement Settings ***\n",
      "  Batch size: 8\n",
      "  Measurement window: 5000 msec\n",
      "  Using synchronous calls for inference\n",
      "  Stabilizing using average latency\n",
      "\n",
      "Request concurrency: 1\n",
      "  Client: \n",
      "    Request count: 51\n",
      "    Throughput: 81.6 infer/sec\n",
      "    Avg latency: 97057 usec (standard deviation 7324 usec)\n",
      "    p50 latency: 96046 usec\n",
      "    p90 latency: 103298 usec\n",
      "    p95 latency: 104323 usec\n",
      "    p99 latency: 134993 usec\n",
      "    Avg gRPC time: 96070 usec ((un)marshal request/response 6917 usec + response wait 89153 usec)\n",
      "  Server: \n",
      "    Inference count: 496\n",
      "    Execution count: 62\n",
      "    Successful request count: 62\n",
      "    Avg request latency: 30308 usec (overhead 3 usec + queue 27 usec + compute input 12828 usec + compute infer 14348 usec + compute output 3102 usec)\n",
      "\n",
      "Inferences/Second vs. Client Average Batch Latency\n",
      "Concurrency: 1, throughput: 81.6 infer/sec, latency 97057 usec\n"
     ]
    }
   ],
   "source": [
    "#batchsize 8\n",
    "!perf_analyzer -m trt_fp16_retina -b 8 -u localhost:8001 -i grpc --concurrency-range 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Measurement Settings ***\n",
      "  Batch size: 1\n",
      "  Measurement window: 5000 msec\n",
      "  Using synchronous calls for inference\n",
      "  Stabilizing using average latency\n",
      "\n",
      "Request concurrency: 1\n",
      "  Client: \n",
      "    Request count: 782\n",
      "    Throughput: 156.4 infer/sec\n",
      "    Avg latency: 6391 usec (standard deviation 1381 usec)\n",
      "    p50 latency: 6302 usec\n",
      "    p90 latency: 6350 usec\n",
      "    p95 latency: 6381 usec\n",
      "    p99 latency: 6659 usec\n",
      "    Avg gRPC time: 6363 usec ((un)marshal request/response 30 usec + response wait 6333 usec)\n",
      "  Server: \n",
      "    Inference count: 941\n",
      "    Execution count: 941\n",
      "    Successful request count: 941\n",
      "    Avg request latency: 5762 usec (overhead 2 usec + queue 18 usec + compute input 1875 usec + compute infer 3858 usec + compute output 9 usec)\n",
      "\n",
      "Inferences/Second vs. Client Average Batch Latency\n",
      "Concurrency: 1, throughput: 156.4 infer/sec, latency 6391 usec\n"
     ]
    }
   ],
   "source": [
    "!perf_analyzer -m trt_fp32_arc -b 1 -u localhost:8001 -i grpc --concurrency-range 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Measurement Settings ***\n",
      "  Batch size: 1\n",
      "  Measurement window: 5000 msec\n",
      "  Using synchronous calls for inference\n",
      "  Stabilizing using average latency\n",
      "\n",
      "Request concurrency: 1\n",
      "  Client: \n",
      "    Request count: 1283\n",
      "    Throughput: 256.6 infer/sec\n",
      "    Avg latency: 3897 usec (standard deviation 1137 usec)\n",
      "    p50 latency: 3847 usec\n",
      "    p90 latency: 3882 usec\n",
      "    p95 latency: 3896 usec\n",
      "    p99 latency: 4198 usec\n",
      "    Avg gRPC time: 3876 usec ((un)marshal request/response 26 usec + response wait 3850 usec)\n",
      "  Server: \n",
      "    Inference count: 1538\n",
      "    Execution count: 1538\n",
      "    Successful request count: 1538\n",
      "    Avg request latency: 3349 usec (overhead 3 usec + queue 14 usec + compute input 1685 usec + compute infer 1640 usec + compute output 7 usec)\n",
      "\n",
      "Inferences/Second vs. Client Average Batch Latency\n",
      "Concurrency: 1, throughput: 256.6 infer/sec, latency 3897 usec\n"
     ]
    }
   ],
   "source": [
    "!perf_analyzer -m trt_fp16_arc -b 1 -u localhost:8001 -i grpc --concurrency-range 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note:- Retinaface here has dynamic batching function whereas Arcface doesn't have it"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
